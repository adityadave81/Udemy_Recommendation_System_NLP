{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Report\n",
    "## Summary : <p> The project that I selected for this course is Udemy Course Recommendation System. In this project I wanted to display Web Scraping as well as Natural Language Processing techniques that I learned during the course. I selected this project because it holds real world value and can be implemented by Udemy at scale. I wanted to show what my thought process and skills look like if I worked for a company as Machine learning consultant. For this project, I will be using Selenium, NLTK and re for procuring and cleaning data. The recommendation system will be implemented using Cosine Similarity and Topic Modeling.</p>\n",
    "\n",
    "## Objectives :\n",
    "\n",
    "## -Webscrape Udemy data for 2000+ Data Science courses.\n",
    "\n",
    "## -Preprocess description text for all courses and create a document to word vector.\n",
    "\n",
    "## -Create a recommendation system using Cosine Similarity scores.\n",
    "\n",
    "## -Improve the recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Imports for text\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Imports for Recommendation System\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Imports for Topic Modeling\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn=nltk.WordNetLemmatizer()\n",
    "st=nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    s = re.sub(r'Description ', '',text) \n",
    "    s = re.sub(r' show more', '',s).strip().lower()\n",
    "    text=re.sub(r'[^\\w\\s]',' ',s).lower()   ### Remove punctuation by removing non-space alpha-num characters\n",
    "    words=re.split(r'\\W+', text) ### Split by remaining non-alphanumeric characters\n",
    "    non_stop_words=[word for word in words if word not in stopword]        ### Remove stopwords\n",
    "    lem_words= [wn.lemmatize(word) for word in non_stop_words]             ### Clean text ==\n",
    "    clean_text= ' '.join(lem_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a DataFrame from Web Scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100_info.txt\n",
      "101_info.txt\n",
      "102_info.txt\n",
      "103_info.txt\n",
      "104_info.txt\n",
      "105_info.txt\n",
      "106_info.txt\n",
      "107_info.txt\n",
      "108_info.txt\n",
      "109_info.txt\n",
      "10_info.txt\n",
      "110_info.txt\n",
      "111_info.txt\n",
      "112_info.txt\n",
      "113_info.txt\n",
      "114_info.txt\n",
      "115_info.txt\n",
      "116_info.txt\n",
      "117_info.txt\n",
      "118_info.txt\n",
      "119_info.txt\n",
      "11_info.txt\n",
      "120_info.txt\n",
      "121_info.txt\n",
      "122_info.txt\n",
      "123_info.txt\n",
      "124_info.txt\n",
      "125_info.txt\n",
      "126_info.txt\n",
      "127_info.txt\n",
      "128_info.txt\n",
      "129_info.txt\n",
      "12_info.txt\n",
      "130_info.txt\n",
      "131_info.txt\n",
      "132_info.txt\n",
      "133_info.txt\n",
      "134_info.txt\n",
      "135_info.txt\n",
      "136_info.txt\n",
      "137_info.txt\n",
      "138_info.txt\n",
      "139_info.txt\n",
      "13_info.txt\n",
      "140_info.txt\n",
      "141_info.txt\n",
      "142_info.txt\n",
      "143_info.txt\n",
      "144_info.txt\n",
      "145_info.txt\n",
      "146_info.txt\n",
      "147_info.txt\n",
      "148_info.txt\n",
      "149_info.txt\n",
      "14_info.txt\n",
      "150_info.txt\n",
      "151_info.txt\n",
      "152_info.txt\n",
      "153_info.txt\n",
      "154_info.txt\n",
      "155_info.txt\n",
      "156_info.txt\n",
      "157_info.txt\n",
      "158_info.txt\n",
      "159_info.txt\n",
      "15_info.txt\n",
      "160_info.txt\n",
      "161_info.txt\n",
      "162_info.txt\n",
      "163_info.txt\n",
      "164_info.txt\n",
      "165_info.txt\n",
      "166_info.txt\n",
      "167_info.txt\n",
      "168_info.txt\n",
      "169_info.txt\n",
      "16_info.txt\n",
      "170_info.txt\n",
      "171_info.txt\n",
      "172_info.txt\n",
      "173_info.txt\n",
      "174_info.txt\n",
      "175_info.txt\n",
      "176_info.txt\n",
      "177_info.txt\n",
      "178_info.txt\n",
      "179_info.txt\n",
      "17_info.txt\n",
      "180_info.txt\n",
      "181_info.txt\n",
      "182_info.txt\n",
      "183_info.txt\n",
      "184_info.txt\n",
      "185_info.txt\n",
      "186_info.txt\n",
      "187_info.txt\n",
      "188_info.txt\n",
      "189_info.txt\n",
      "18_info.txt\n",
      "190_info.txt\n",
      "191_info.txt\n",
      "192_info.txt\n",
      "193_info.txt\n",
      "194_info.txt\n",
      "195_info.txt\n",
      "196_info.txt\n",
      "197_info.txt\n",
      "198_info.txt\n",
      "199_info.txt\n",
      "19_info.txt\n",
      "1_info.txt\n",
      "200_info.txt\n",
      "201_info.txt\n",
      "202_info.txt\n",
      "203_info.txt\n",
      "204_info.txt\n",
      "205_info.txt\n",
      "206_info.txt\n",
      "207_info.txt\n",
      "208_info.txt\n",
      "209_info.txt\n",
      "20_info.txt\n",
      "210_info.txt\n",
      "211_info.txt\n",
      "212_info.txt\n",
      "213_info.txt\n",
      "214_info.txt\n",
      "215_info.txt\n",
      "216_info.txt\n",
      "217_info.txt\n",
      "218_info.txt\n",
      "219_info.txt\n",
      "21_info.txt\n",
      "220_info.txt\n",
      "221_info.txt\n",
      "222_info.txt\n",
      "223_info.txt\n",
      "224_info.txt\n",
      "225_info.txt\n",
      "226_info.txt\n",
      "227_info.txt\n",
      "228_info.txt\n",
      "229_info.txt\n",
      "22_info.txt\n",
      "230_info.txt\n",
      "231_info.txt\n",
      "232_info.txt\n",
      "233_info.txt\n",
      "234_info.txt\n",
      "235_info.txt\n",
      "236_info.txt\n",
      "237_info.txt\n",
      "238_info.txt\n",
      "239_info.txt\n",
      "23_info.txt\n",
      "240_info.txt\n",
      "241_info.txt\n",
      "242_info.txt\n",
      "243_info.txt\n",
      "244_info.txt\n",
      "245_info.txt\n",
      "246_info.txt\n",
      "247_info.txt\n",
      "248_info.txt\n",
      "249_info.txt\n",
      "24_info.txt\n",
      "250_info.txt\n",
      "251_info.txt\n",
      "252_info.txt\n",
      "253_info.txt\n",
      "254_info.txt\n",
      "255_info.txt\n",
      "256_info.txt\n",
      "257_info.txt\n",
      "258_info.txt\n",
      "259_info.txt\n",
      "25_info.txt\n",
      "260_info.txt\n",
      "261_info.txt\n",
      "262_info.txt\n",
      "263_info.txt\n",
      "264_info.txt\n",
      "265_info.txt\n",
      "266_info.txt\n",
      "267_info.txt\n",
      "268_info.txt\n",
      "269_info.txt\n",
      "26_info.txt\n",
      "270_info.txt\n",
      "271_info.txt\n",
      "272_info.txt\n",
      "273_info.txt\n",
      "274_info.txt\n",
      "275_info.txt\n",
      "276_info.txt\n",
      "277_info.txt\n",
      "278_info.txt\n",
      "279_info.txt\n",
      "27_info.txt\n",
      "280_info.txt\n",
      "281_info.txt\n",
      "282_info.txt\n",
      "283_info.txt\n",
      "284_info.txt\n",
      "285_info.txt\n",
      "286_info.txt\n",
      "287_info.txt\n",
      "288_info.txt\n",
      "289_info.txt\n",
      "28_info.txt\n",
      "290_info.txt\n",
      "291_info.txt\n",
      "292_info.txt\n",
      "293_info.txt\n",
      "294_info.txt\n",
      "295_info.txt\n",
      "296_info.txt\n",
      "297_info.txt\n",
      "298_info.txt\n",
      "299_info.txt\n",
      "29_info.txt\n",
      "2_info.txt\n",
      "300_info.txt\n",
      "301_info.txt\n",
      "302_info.txt\n",
      "303_info.txt\n",
      "304_info.txt\n",
      "305_info.txt\n",
      "306_info.txt\n",
      "307_info.txt\n",
      "308_info.txt\n",
      "309_info.txt\n",
      "30_info.txt\n",
      "310_info.txt\n",
      "311_info.txt\n",
      "312_info.txt\n",
      "313_info.txt\n",
      "314_info.txt\n",
      "315_info.txt\n",
      "316_info.txt\n",
      "317_info.txt\n",
      "318_info.txt\n",
      "319_info.txt\n",
      "31_info.txt\n",
      "320_info.txt\n",
      "321_info.txt\n",
      "322_info.txt\n",
      "323_info.txt\n",
      "324_info.txt\n",
      "325_info.txt\n",
      "326_info.txt\n",
      "327_info.txt\n",
      "328_info.txt\n",
      "329_info.txt\n",
      "32_info.txt\n",
      "330_info.txt\n",
      "331_info.txt\n",
      "332_info.txt\n",
      "333_info.txt\n",
      "334_info.txt\n",
      "335_info.txt\n",
      "336_info.txt\n",
      "337_info.txt\n",
      "338_info.txt\n",
      "339_info.txt\n",
      "33_info.txt\n",
      "340_info.txt\n",
      "341_info.txt\n",
      "342_info.txt\n",
      "343_info.txt\n",
      "344_info.txt\n",
      "345_info.txt\n",
      "346_info.txt\n",
      "347_info.txt\n",
      "348_info.txt\n",
      "349_info.txt\n",
      "34_info.txt\n",
      "350_info.txt\n",
      "351_info.txt\n",
      "352_info.txt\n",
      "353_info.txt\n",
      "354_info.txt\n",
      "355_info.txt\n",
      "356_info.txt\n",
      "357_info.txt\n",
      "358_info.txt\n",
      "359_info.txt\n",
      "35_info.txt\n",
      "360_info.txt\n",
      "361_info.txt\n",
      "362_info.txt\n",
      "363_info.txt\n",
      "364_info.txt\n",
      "365_info.txt\n",
      "366_info.txt\n",
      "367_info.txt\n",
      "368_info.txt\n",
      "369_info.txt\n",
      "36_info.txt\n",
      "370_info.txt\n",
      "371_info.txt\n",
      "372_info.txt\n",
      "373_info.txt\n",
      "374_info.txt\n",
      "375_info.txt\n",
      "376_info.txt\n",
      "377_info.txt\n",
      "378_info.txt\n",
      "379_info.txt\n",
      "37_info.txt\n",
      "380_info.txt\n",
      "381_info.txt\n",
      "382_info.txt\n",
      "383_info.txt\n",
      "384_info.txt\n",
      "385_info.txt\n",
      "386_info.txt\n",
      "387_info.txt\n",
      "388_info.txt\n",
      "389_info.txt\n",
      "38_info.txt\n",
      "390_info.txt\n",
      "391_info.txt\n",
      "392_info.txt\n",
      "393_info.txt\n",
      "394_info.txt\n",
      "395_info.txt\n",
      "396_info.txt\n",
      "397_info.txt\n",
      "398_info.txt\n",
      "399_info.txt\n",
      "39_info.txt\n",
      "3_info.txt\n",
      "400_info.txt\n",
      "401_info.txt\n",
      "402_info.txt\n",
      "403_info.txt\n",
      "404_info.txt\n",
      "405_info.txt\n",
      "406_info.txt\n",
      "407_info.txt\n",
      "408_info.txt\n",
      "409_info.txt\n",
      "40_info.txt\n",
      "410_info.txt\n",
      "411_info.txt\n",
      "412_info.txt\n",
      "413_info.txt\n",
      "414_info.txt\n",
      "415_info.txt\n",
      "416_info.txt\n",
      "41_info.txt\n",
      "42_info.txt\n",
      "43_info.txt\n",
      "44_info.txt\n",
      "45_info.txt\n",
      "46_info.txt\n",
      "47_info.txt\n",
      "48_info.txt\n",
      "49_info.txt\n",
      "4_info.txt\n",
      "50_info.txt\n",
      "51_info.txt\n",
      "52_info.txt\n",
      "53_info.txt\n",
      "54_info.txt\n",
      "55_info.txt\n",
      "56_info.txt\n",
      "57_info.txt\n",
      "58_info.txt\n",
      "59_info.txt\n",
      "5_info.txt\n",
      "60_info.txt\n",
      "61_info.txt\n",
      "62_info.txt\n",
      "63_info.txt\n",
      "64_info.txt\n",
      "65_info.txt\n",
      "66_info.txt\n",
      "67_info.txt\n",
      "68_info.txt\n",
      "69_info.txt\n",
      "6_info.txt\n",
      "70_info.txt\n",
      "71_info.txt\n",
      "72_info.txt\n",
      "73_info.txt\n",
      "74_info.txt\n",
      "75_info.txt\n",
      "76_info.txt\n",
      "77_info.txt\n",
      "78_info.txt\n",
      "79_info.txt\n",
      "7_info.txt\n",
      "80_info.txt\n",
      "81_info.txt\n",
      "82_info.txt\n",
      "83_info.txt\n",
      "84_info.txt\n",
      "85_info.txt\n",
      "86_info.txt\n",
      "87_info.txt\n",
      "88_info.txt\n",
      "89_info.txt\n",
      "8_info.txt\n",
      "90_info.txt\n",
      "91_info.txt\n",
      "92_info.txt\n",
      "93_info.txt\n",
      "94_info.txt\n",
      "95_info.txt\n",
      "96_info.txt\n",
      "97_info.txt\n",
      "98_info.txt\n",
      "99_info.txt\n",
      "9_info.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "files = []\n",
    "for infile in sorted(glob.glob('*_info.txt'), key=numericalSort):\n",
    "    files.append(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(file,'r',encoding=\"utf8\") as f:\n",
    "        data=f.read().split('\\n\\n')\n",
    "        data=[i.split('\\n') for i in data]\n",
    "        s=pd.DataFrame([data[0][0:15]],columns=['id', 'title', 'purpose', 'total_enrollment', 'rating', 'number_ratings', 'last_update_date', 'what_you_get', 'prerequisites', 'description', 'five_stars', 'four_stars', 'three_stars', 'two_stars', 'one_star'])\n",
    "        df =pd.concat([df, s], ignore_index=True) \n",
    "\n",
    "#df = df.iloc[1: , :]\n",
    "#df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_clean'] = df['description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:/Users/15512/course_list_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = pd.concat([df, df2[:2001]], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 26)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'purpose', 'total_enrollment', 'rating',\n",
       "       'number_ratings', 'last_update_date', 'what_you_get', 'prerequisites',\n",
       "       'description', 'five_stars', 'four_stars', 'three_stars', 'two_stars',\n",
       "       'one_star', 'description_clean', 'id', 'name', 'link', 'seller',\n",
       "       'price', 'original_price', 'lectures', 'hours', 'level',\n",
       "       'Tue Dec 14 05:56:01 2021'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.drop(complete_data.columns[[4, 5, 16, 17, 25]], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>what_you_get</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>description</th>\n",
       "      <th>five_stars</th>\n",
       "      <th>four_stars</th>\n",
       "      <th>three_stars</th>\n",
       "      <th>two_stars</th>\n",
       "      <th>one_star</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning A Z   Hands On Python   R In ...</td>\n",
       "      <td>Learn to create Machine Learning Algorithms in...</td>\n",
       "      <td>833575</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Master Machine Learning on Python   R Have a g...</td>\n",
       "      <td>Requirements Just some high school mathematics...</td>\n",
       "      <td>Description Interested in the field of Machine...</td>\n",
       "      <td>54%</td>\n",
       "      <td>34%</td>\n",
       "      <td>9%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>interested field machine learning course cours...</td>\n",
       "      <td>https://www.udemy.com/course/machinelearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>320</td>\n",
       "      <td>44.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python for Data Science and Machine Learning B...</td>\n",
       "      <td>Learn how to use NumPy, Pandas, Seaborn , Matp...</td>\n",
       "      <td>501618</td>\n",
       "      <td>5/2020</td>\n",
       "      <td>Use Python for Data Science and Machine Learni...</td>\n",
       "      <td>Requirements Some programming experience Admin...</td>\n",
       "      <td>Description Are you ready to start your path t...</td>\n",
       "      <td>56%</td>\n",
       "      <td>36%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>&lt; 1%</td>\n",
       "      <td>ready start path becoming data scientist compr...</td>\n",
       "      <td>https://www.udemy.com/course/python-for-data-s...</td>\n",
       "      <td>Jose Portilla</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>165</td>\n",
       "      <td>25</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Data Science Course 2021  Complete Data Sc...</td>\n",
       "      <td>Complete Data Science Training: Mathematics, S...</td>\n",
       "      <td>452453</td>\n",
       "      <td>11/2021</td>\n",
       "      <td>The course provides the entire toolbox you nee...</td>\n",
       "      <td>Requirements No prior experience is required  ...</td>\n",
       "      <td>Description The Problem Data scientist is one ...</td>\n",
       "      <td>54%</td>\n",
       "      <td>35%</td>\n",
       "      <td>9%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>problem data scientist one best suited profess...</td>\n",
       "      <td>https://www.udemy.com/course/the-data-science-...</td>\n",
       "      <td>365 Careers  365 Careers Team</td>\n",
       "      <td>15.99</td>\n",
       "      <td>94.99</td>\n",
       "      <td>488</td>\n",
       "      <td>30</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R Programming A Z   R For Data Science With Re...</td>\n",
       "      <td>Learn Programming In R And R Studio. Data Anal...</td>\n",
       "      <td>221022</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Learn to program in R at a good level Learn ho...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description Learn R Programming by doing! Ther...</td>\n",
       "      <td>59%</td>\n",
       "      <td>33%</td>\n",
       "      <td>6%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>learn r programming lot r course lecture howev...</td>\n",
       "      <td>https://www.udemy.com/course/r-programming/</td>\n",
       "      <td>Kirill Eremenko  Ligency I Team  Ligency Team</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>82</td>\n",
       "      <td>10.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deep Learning A Z   Hands On Artificial Neural...</td>\n",
       "      <td>Learn to create Deep Learning Algorithms in Py...</td>\n",
       "      <td>322765</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Understand the intuition behind Artificial Neu...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description *** As seen on Kickstarter *** Art...</td>\n",
       "      <td>54%</td>\n",
       "      <td>34%</td>\n",
       "      <td>9%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>seen kickstarter artificial intelligence grow...</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>173</td>\n",
       "      <td>22.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Machine Learning A Z   Hands On Python   R In ...   \n",
       "1  Python for Data Science and Machine Learning B...   \n",
       "2  The Data Science Course 2021  Complete Data Sc...   \n",
       "3  R Programming A Z   R For Data Science With Re...   \n",
       "4  Deep Learning A Z   Hands On Artificial Neural...   \n",
       "\n",
       "                                             purpose total_enrollment  \\\n",
       "0  Learn to create Machine Learning Algorithms in...           833575   \n",
       "1  Learn how to use NumPy, Pandas, Seaborn , Matp...           501618   \n",
       "2  Complete Data Science Training: Mathematics, S...           452453   \n",
       "3  Learn Programming In R And R Studio. Data Anal...           221022   \n",
       "4  Learn to create Deep Learning Algorithms in Py...           322765   \n",
       "\n",
       "  last_update_date                                       what_you_get  \\\n",
       "0          12/2021  Master Machine Learning on Python   R Have a g...   \n",
       "1           5/2020  Use Python for Data Science and Machine Learni...   \n",
       "2          11/2021  The course provides the entire toolbox you nee...   \n",
       "3          12/2021  Learn to program in R at a good level Learn ho...   \n",
       "4          12/2021  Understand the intuition behind Artificial Neu...   \n",
       "\n",
       "                                       prerequisites  \\\n",
       "0  Requirements Just some high school mathematics...   \n",
       "1  Requirements Some programming experience Admin...   \n",
       "2  Requirements No prior experience is required  ...   \n",
       "3                                       Requirements   \n",
       "4                                       Requirements   \n",
       "\n",
       "                                         description five_stars four_stars  \\\n",
       "0  Description Interested in the field of Machine...        54%        34%   \n",
       "1  Description Are you ready to start your path t...        56%        36%   \n",
       "2  Description The Problem Data scientist is one ...        54%        35%   \n",
       "3  Description Learn R Programming by doing! Ther...        59%        33%   \n",
       "4  Description *** As seen on Kickstarter *** Art...        54%        34%   \n",
       "\n",
       "  three_stars two_stars one_star  \\\n",
       "0          9%        2%       1%   \n",
       "1          7%        1%     < 1%   \n",
       "2          9%        1%       1%   \n",
       "3          6%        1%       1%   \n",
       "4          9%        2%       1%   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0  interested field machine learning course cours...   \n",
       "1  ready start path becoming data scientist compr...   \n",
       "2  problem data scientist one best suited profess...   \n",
       "3  learn r programming lot r course lecture howev...   \n",
       "4   seen kickstarter artificial intelligence grow...   \n",
       "\n",
       "                                                link  \\\n",
       "0      https://www.udemy.com/course/machinelearning/   \n",
       "1  https://www.udemy.com/course/python-for-data-s...   \n",
       "2  https://www.udemy.com/course/the-data-science-...   \n",
       "3        https://www.udemy.com/course/r-programming/   \n",
       "4         https://www.udemy.com/course/deeplearning/   \n",
       "\n",
       "                                              seller  price  original_price  \\\n",
       "0  Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99           84.99   \n",
       "1                                      Jose Portilla  13.99           84.99   \n",
       "2                      365 Careers  365 Careers Team  15.99           94.99   \n",
       "3      Kirill Eremenko  Ligency I Team  Ligency Team  13.99           84.99   \n",
       "4  Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99           84.99   \n",
       "\n",
       "   lectures  hours       level  \n",
       "0       320  44.5   All Levels  \n",
       "1       165    25   All Levels  \n",
       "2       488    30   All Levels  \n",
       "3        82  10.5   All Levels  \n",
       "4       173  22.5   All Levels  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the dataframe to .csv for future use.\n",
    "complete_data.to_csv('complete_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function used for Recommending courses\n",
    "def Recommend():\n",
    "    input_string = input('Enter the description of Udemy Course:')\n",
    "    input_string_clean = clean(input_string)\n",
    "    input_string_v = tfidf_trans.transform([input_string_clean])\n",
    "    cosine_simil = cosine_similarity(input_string_v, X_tfidf)[0]\n",
    "    sorted_index= np.argsort(cosine_simil)[::-1]\n",
    "    return pd.DataFrame([complete_data.iloc[i].to_numpy().T for i in sorted_index], columns = complete_data.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans=TfidfVectorizer()\n",
    "X_tfidf=tfidf_trans.fit_transform(complete_data['description_clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<427x4028 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 24818 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results when we use Deep Learning course description as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the description of Udemy Course:You've definitely heard of AI and Deep Learning. But when you ask yourself, what is my position with respect to this new industrial revolution, that might lead you to another fundamental question: am I a consumer or a creator? For most people nowadays, the answer would be, a consumer.  But what if you could also become a creator?  What if there was a way for you to easily break into the World of Artificial Intelligence and build amazing applications which leverage the latest technology to make the World a better place?  Sounds too good to be true, doesn't it?  But there actually is a way..  Computer Vision is by far the easiest way of becoming a creator.  And it's not only the easiest way, it's also the branch of AI where there is the most to create.  Why? You'll ask.  That's because Computer Vision is applied everywhere. From health to retail to entertainment - the list goes on. Computer Vision is already a $18 Billion market and is growing exponentially.  Just think of tumor detection in patient MRI brain scans. How many more lives are saved every day simply because a computer can analyze 10,000x more images than a human?  And what if you find an industry where Computer Vision is not yet applied? Then all the better! That means there's a business opportunity which you can take advantage of.  So now that raises the question: how do you break into the World of Computer Vision?  Up until now, computer vision has for the most part been a maze. A growing maze.  As the number of codes, libraries and tools in CV grows, it becomes harder and harder to not get lost.  On top of that, not only do you need to know how to use it - you also need to know how it works to maximise the advantage of using Computer Vision.  To this problem we want to bring...   Computer Vision A-Z.  With this brand new course you will not only learn how the most popular computer vision methods work, but you will also learn to apply them in practice!  Can't wait to see you inside the class,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>what_you_get</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>description</th>\n",
       "      <th>five_stars</th>\n",
       "      <th>four_stars</th>\n",
       "      <th>three_stars</th>\n",
       "      <th>two_stars</th>\n",
       "      <th>one_star</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Learning and Computer Vision A Z   OpenCV...</td>\n",
       "      <td>Become a Wizard of all the latest Computer Vis...</td>\n",
       "      <td>43258</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Have a toolbox of the most powerful Computer V...</td>\n",
       "      <td>Requirements Only High School Maths Basic Pyth...</td>\n",
       "      <td>Description *** AS SEEN ON KICKSTARTER *** You...</td>\n",
       "      <td>53%</td>\n",
       "      <td>32%</td>\n",
       "      <td>10%</td>\n",
       "      <td>3%</td>\n",
       "      <td>2%</td>\n",
       "      <td>seen kickstarter definitely heard ai deep lea...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-a-z/</td>\n",
       "      <td>Hadelin de Ponteves  Kirill Eremenko  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Vision Masterclass</td>\n",
       "      <td>Learn in practice everything you need to know ...</td>\n",
       "      <td>26710</td>\n",
       "      <td>10/2021</td>\n",
       "      <td>Understand the basic intuition about Cascade a...</td>\n",
       "      <td>Requirements Programming logic Basic Python pr...</td>\n",
       "      <td>Description Computer Vision is a subarea of Ar...</td>\n",
       "      <td>51%</td>\n",
       "      <td>33%</td>\n",
       "      <td>13%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>computer vision subarea artificial intelligenc...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-m...</td>\n",
       "      <td>Jones Granatyr  Ligency I Team  Gabriel Alves</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>228</td>\n",
       "      <td>25.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Vision In Python  Face Detection   Im...</td>\n",
       "      <td>Learn Computer Vision With OpenCV In Python! M...</td>\n",
       "      <td>16702</td>\n",
       "      <td>8/2021</td>\n",
       "      <td>Use OpenCV to work with image files Understand...</td>\n",
       "      <td>Requirements Basic Python programming knowledge</td>\n",
       "      <td>Description Computer vision is an interdiscipl...</td>\n",
       "      <td>46%</td>\n",
       "      <td>39%</td>\n",
       "      <td>11%</td>\n",
       "      <td>3%</td>\n",
       "      <td>1%</td>\n",
       "      <td>computer vision interdisciplinary field deal c...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-i...</td>\n",
       "      <td>Emenwa Global  Zoolord Academy</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Vision  Face Recognition Quick Starte...</td>\n",
       "      <td>Quickly Build Python Deep Learning based Face ...</td>\n",
       "      <td>3229</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Face Detection from Images Face Detection from...</td>\n",
       "      <td>Requirements A decent configuration computer a...</td>\n",
       "      <td>Description Hi There!  welcome to my new cours...</td>\n",
       "      <td>45%</td>\n",
       "      <td>42%</td>\n",
       "      <td>10%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>hi welcome new course face recognition deep le...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-f...</td>\n",
       "      <td>Abhilash Nelson</td>\n",
       "      <td>15.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>64</td>\n",
       "      <td>6.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automated Multiple Face Recognition AI Using P...</td>\n",
       "      <td>Learn about OpenCv Basics, Face Recognition in...</td>\n",
       "      <td>19677</td>\n",
       "      <td>11/2019</td>\n",
       "      <td>Automated Multiple Face Recognition in an imag...</td>\n",
       "      <td>Requirements Basics of Python Programming</td>\n",
       "      <td>Description Hello, welcome to the Amazing worl...</td>\n",
       "      <td>27%</td>\n",
       "      <td>31%</td>\n",
       "      <td>27%</td>\n",
       "      <td>9%</td>\n",
       "      <td>6%</td>\n",
       "      <td>hello welcome amazing world computer vision co...</td>\n",
       "      <td>https://www.udemy.com/course/automated-multipl...</td>\n",
       "      <td>Nishit Maru  Three Millennials</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Deep Learning and Computer Vision A Z   OpenCV...   \n",
       "1                        Computer Vision Masterclass   \n",
       "2  Computer Vision In Python  Face Detection   Im...   \n",
       "3  Computer Vision  Face Recognition Quick Starte...   \n",
       "4  Automated Multiple Face Recognition AI Using P...   \n",
       "\n",
       "                                             purpose total_enrollment  \\\n",
       "0  Become a Wizard of all the latest Computer Vis...            43258   \n",
       "1  Learn in practice everything you need to know ...            26710   \n",
       "2  Learn Computer Vision With OpenCV In Python! M...            16702   \n",
       "3  Quickly Build Python Deep Learning based Face ...             3229   \n",
       "4  Learn about OpenCv Basics, Face Recognition in...            19677   \n",
       "\n",
       "  last_update_date                                       what_you_get  \\\n",
       "0          12/2021  Have a toolbox of the most powerful Computer V...   \n",
       "1          10/2021  Understand the basic intuition about Cascade a...   \n",
       "2           8/2021  Use OpenCV to work with image files Understand...   \n",
       "3          12/2021  Face Detection from Images Face Detection from...   \n",
       "4          11/2019  Automated Multiple Face Recognition in an imag...   \n",
       "\n",
       "                                       prerequisites  \\\n",
       "0  Requirements Only High School Maths Basic Pyth...   \n",
       "1  Requirements Programming logic Basic Python pr...   \n",
       "2    Requirements Basic Python programming knowledge   \n",
       "3  Requirements A decent configuration computer a...   \n",
       "4          Requirements Basics of Python Programming   \n",
       "\n",
       "                                         description five_stars four_stars  \\\n",
       "0  Description *** AS SEEN ON KICKSTARTER *** You...        53%        32%   \n",
       "1  Description Computer Vision is a subarea of Ar...        51%        33%   \n",
       "2  Description Computer vision is an interdiscipl...        46%        39%   \n",
       "3  Description Hi There!  welcome to my new cours...        45%        42%   \n",
       "4  Description Hello, welcome to the Amazing worl...        27%        31%   \n",
       "\n",
       "  three_stars two_stars one_star  \\\n",
       "0         10%        3%       2%   \n",
       "1         13%        2%       1%   \n",
       "2         11%        3%       1%   \n",
       "3         10%        2%       1%   \n",
       "4         27%        9%       6%   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0   seen kickstarter definitely heard ai deep lea...   \n",
       "1  computer vision subarea artificial intelligenc...   \n",
       "2  computer vision interdisciplinary field deal c...   \n",
       "3  hi welcome new course face recognition deep le...   \n",
       "4  hello welcome amazing world computer vision co...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.udemy.com/course/computer-vision-a-z/   \n",
       "1  https://www.udemy.com/course/computer-vision-m...   \n",
       "2  https://www.udemy.com/course/computer-vision-i...   \n",
       "3  https://www.udemy.com/course/computer-vision-f...   \n",
       "4  https://www.udemy.com/course/automated-multipl...   \n",
       "\n",
       "                                              seller  price  original_price  \\\n",
       "0  Hadelin de Ponteves  Kirill Eremenko  Ligency ...  13.99           84.99   \n",
       "1      Jones Granatyr  Ligency I Team  Gabriel Alves  13.99           84.99   \n",
       "2                     Emenwa Global  Zoolord Academy  13.99           84.99   \n",
       "3                                    Abhilash Nelson  15.99           99.99   \n",
       "4                     Nishit Maru  Three Millennials  13.99           84.99   \n",
       "\n",
       "   lectures  hours       level  \n",
       "0        85    11   All Levels  \n",
       "1       228  25.5   All Levels  \n",
       "2        61    11   All Levels  \n",
       "3        64   6.5   All Levels  \n",
       "4        10     2   All Levels  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results when we use normal python course description as Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the description of Udemy Course:Are you ready to start your path to becoming a Data Scientist!   This comprehensive course will be your guide to learning how to use the power of Python to analyze data, create beautiful visualizations, and use powerful machine learning algorithms!  Data Scientist has been ranked the number one job on Glassdoor and the average salary of a data scientist is over $120,000 in the United States according to Indeed! Data Science is a rewarding career that allows you to solve some of the world's most interesting problems!  This course is designed for both beginners with some programming experience or experienced developers looking to make the jump to Data Science!  This comprehensive course is comparable to other Data Science bootcamps that usually cost thousands of dollars, but now you can learn all that information at a fraction of the cost! With over 100 HD video lectures and detailed code notebooks for every lecture this is one of the most comprehensive course for data science and machine learning on Udemy!  We'll teach you how to program with Python, how to create amazing data visualizations, and how to use Machine Learning with Python! Here a just a few of the topics we will be learning:  Programming with Python NumPy with Python Using pandas Data Frames to solve complex tasks Use pandas to handle Excel Files Web scraping with python Connect Python to SQL Use matplotlib and seaborn for data visualizations Use plotly for interactive visualizations Machine Learning with SciKit Learn, including: Linear Regression K Nearest Neighbors K Means Clustering Decision Trees Random Forests Natural Language Processing Neural Nets and Deep Learning Support Vector Machines and much, much more! Enroll in the course and become a data scientist today!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>what_you_get</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>description</th>\n",
       "      <th>five_stars</th>\n",
       "      <th>four_stars</th>\n",
       "      <th>three_stars</th>\n",
       "      <th>two_stars</th>\n",
       "      <th>one_star</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python for Data Science and Machine Learning B...</td>\n",
       "      <td>Learn how to use NumPy, Pandas, Seaborn , Matp...</td>\n",
       "      <td>501618</td>\n",
       "      <td>5/2020</td>\n",
       "      <td>Use Python for Data Science and Machine Learni...</td>\n",
       "      <td>Requirements Some programming experience Admin...</td>\n",
       "      <td>Description Are you ready to start your path t...</td>\n",
       "      <td>56%</td>\n",
       "      <td>36%</td>\n",
       "      <td>7%</td>\n",
       "      <td>1%</td>\n",
       "      <td>&lt; 1%</td>\n",
       "      <td>ready start path becoming data scientist compr...</td>\n",
       "      <td>https://www.udemy.com/course/python-for-data-s...</td>\n",
       "      <td>Jose Portilla</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>165</td>\n",
       "      <td>25</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science and Machine Learning Bootcamp with R</td>\n",
       "      <td>Learn how to use the R programming language fo...</td>\n",
       "      <td>76489</td>\n",
       "      <td>12/2020</td>\n",
       "      <td>Program in R Use R for Data Analysis Create Da...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description Data Scientist has been ranked the...</td>\n",
       "      <td>59%</td>\n",
       "      <td>34%</td>\n",
       "      <td>6%</td>\n",
       "      <td>1%</td>\n",
       "      <td>&lt; 1%</td>\n",
       "      <td>data scientist ranked number one job glassdoor...</td>\n",
       "      <td>https://www.udemy.com/course/data-science-and-...</td>\n",
       "      <td>Jose Portilla</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science A Z   Machine Learning with Pytho...</td>\n",
       "      <td>By Data Scientist / IITian for Beginners . Dat...</td>\n",
       "      <td>665</td>\n",
       "      <td>3/2020</td>\n",
       "      <td>Data Science   Machine Learning How to do mach...</td>\n",
       "      <td>Requirements No Prerequisite</td>\n",
       "      <td>Description Interested in the field of Data Sc...</td>\n",
       "      <td>44%</td>\n",
       "      <td>29%</td>\n",
       "      <td>17%</td>\n",
       "      <td>6%</td>\n",
       "      <td>4%</td>\n",
       "      <td>interested field data science machine learning...</td>\n",
       "      <td>https://www.udemy.com/course/machine-learning-...</td>\n",
       "      <td>Arpan Gupta</td>\n",
       "      <td>13.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>90</td>\n",
       "      <td>12.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science and Machine Learning using Python...</td>\n",
       "      <td>Numpy Pandas Matplotlib Seaborn Ploty Machine ...</td>\n",
       "      <td>2476</td>\n",
       "      <td>2/2020</td>\n",
       "      <td>Python to analyze data  create state of the ar...</td>\n",
       "      <td>Requirements A PC and passion to be successful...</td>\n",
       "      <td>Description Greetings,  I am so excited to lea...</td>\n",
       "      <td>52%</td>\n",
       "      <td>35%</td>\n",
       "      <td>10%</td>\n",
       "      <td>1%</td>\n",
       "      <td>2%</td>\n",
       "      <td>greeting excited learn started path becoming d...</td>\n",
       "      <td>https://www.udemy.com/course/data-science-and-...</td>\n",
       "      <td>Dr  Junaid Qazi  PhD</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>111</td>\n",
       "      <td>25</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Visualization in Python Masterclass   Beg...</td>\n",
       "      <td>Visualisation in matplotlib, Seaborn, Plotly &amp;...</td>\n",
       "      <td>25790</td>\n",
       "      <td>11/2021</td>\n",
       "      <td>Learn Complete Exploratory Data Analysis on th...</td>\n",
       "      <td>Requirements No introductory skill level of Py...</td>\n",
       "      <td>Description Are you ready to start your path t...</td>\n",
       "      <td>60%</td>\n",
       "      <td>30%</td>\n",
       "      <td>8%</td>\n",
       "      <td>1%</td>\n",
       "      <td>1%</td>\n",
       "      <td>ready start path becoming data scientist kgp t...</td>\n",
       "      <td>https://www.udemy.com/course/complete-data-vis...</td>\n",
       "      <td>Laxmi Kant</td>\n",
       "      <td>14.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>225</td>\n",
       "      <td>22</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Python for Data Science and Machine Learning B...   \n",
       "1  Data Science and Machine Learning Bootcamp with R   \n",
       "2  Data Science A Z   Machine Learning with Pytho...   \n",
       "3  Data Science and Machine Learning using Python...   \n",
       "4  Data Visualization in Python Masterclass   Beg...   \n",
       "\n",
       "                                             purpose total_enrollment  \\\n",
       "0  Learn how to use NumPy, Pandas, Seaborn , Matp...           501618   \n",
       "1  Learn how to use the R programming language fo...            76489   \n",
       "2  By Data Scientist / IITian for Beginners . Dat...              665   \n",
       "3  Numpy Pandas Matplotlib Seaborn Ploty Machine ...             2476   \n",
       "4  Visualisation in matplotlib, Seaborn, Plotly &...            25790   \n",
       "\n",
       "  last_update_date                                       what_you_get  \\\n",
       "0           5/2020  Use Python for Data Science and Machine Learni...   \n",
       "1          12/2020  Program in R Use R for Data Analysis Create Da...   \n",
       "2           3/2020  Data Science   Machine Learning How to do mach...   \n",
       "3           2/2020  Python to analyze data  create state of the ar...   \n",
       "4          11/2021  Learn Complete Exploratory Data Analysis on th...   \n",
       "\n",
       "                                       prerequisites  \\\n",
       "0  Requirements Some programming experience Admin...   \n",
       "1                                       Requirements   \n",
       "2                       Requirements No Prerequisite   \n",
       "3  Requirements A PC and passion to be successful...   \n",
       "4  Requirements No introductory skill level of Py...   \n",
       "\n",
       "                                         description five_stars four_stars  \\\n",
       "0  Description Are you ready to start your path t...        56%        36%   \n",
       "1  Description Data Scientist has been ranked the...        59%        34%   \n",
       "2  Description Interested in the field of Data Sc...        44%        29%   \n",
       "3  Description Greetings,  I am so excited to lea...        52%        35%   \n",
       "4  Description Are you ready to start your path t...        60%        30%   \n",
       "\n",
       "  three_stars two_stars one_star  \\\n",
       "0          7%        1%     < 1%   \n",
       "1          6%        1%     < 1%   \n",
       "2         17%        6%       4%   \n",
       "3         10%        1%       2%   \n",
       "4          8%        1%       1%   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0  ready start path becoming data scientist compr...   \n",
       "1  data scientist ranked number one job glassdoor...   \n",
       "2  interested field data science machine learning...   \n",
       "3  greeting excited learn started path becoming d...   \n",
       "4  ready start path becoming data scientist kgp t...   \n",
       "\n",
       "                                                link                seller  \\\n",
       "0  https://www.udemy.com/course/python-for-data-s...         Jose Portilla   \n",
       "1  https://www.udemy.com/course/data-science-and-...         Jose Portilla   \n",
       "2  https://www.udemy.com/course/machine-learning-...           Arpan Gupta   \n",
       "3  https://www.udemy.com/course/data-science-and-...  Dr  Junaid Qazi  PhD   \n",
       "4  https://www.udemy.com/course/complete-data-vis...            Laxmi Kant   \n",
       "\n",
       "   price  original_price  lectures  hours       level  \n",
       "0  13.99           84.99       165    25   All Levels  \n",
       "1  13.99           84.99       128    18   All Levels  \n",
       "2  13.99           19.99        90  12.5   All Levels  \n",
       "3  13.99           84.99       111    25   All Levels  \n",
       "4  14.99           19.99       225    22   All Levels  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=corpora.Dictionary(complete_data['description_clean'].str.split(' '))\n",
    "corpus=[dictionary.doc2bow(text) for text in complete_data['description_clean'].str.split(' ')]\n",
    "lda=models.LdaModel(corpus, id2word=dictionary, num_topics=5)\n",
    "\n",
    "for i in  range(5):\n",
    "    print(lda.print_topic(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=corpora.Dictionary(complete_data['description_clean'].str.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[dictionary.doc2bow(text) for text in complete_data['description_clean'].str.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=models.LdaModel(corpus, id2word=dictionary, num_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029*\"learning\" + 0.024*\"course\" + 0.023*\"machine\" + 0.020*\"data\" + 0.010*\"python\" + 0.010*\"learn\" + 0.008*\"show\" + 0.007*\"using\" + 0.006*\"algorithm\" + 0.006*\"analysis\"\n",
      "0.039*\"data\" + 0.030*\"course\" + 0.016*\"machine\" + 0.014*\"learning\" + 0.013*\"science\" + 0.012*\"show\" + 0.009*\"model\" + 0.009*\"learn\" + 0.008*\"r\" + 0.007*\"using\"\n",
      "0.037*\"learning\" + 0.030*\"data\" + 0.024*\"course\" + 0.022*\"machine\" + 0.011*\"show\" + 0.009*\"learn\" + 0.009*\"science\" + 0.009*\"r\" + 0.008*\"deep\" + 0.007*\"ai\"\n",
      "0.037*\"course\" + 0.027*\"data\" + 0.023*\"learning\" + 0.014*\"show\" + 0.011*\"science\" + 0.010*\"learn\" + 0.010*\"deep\" + 0.009*\"machine\" + 0.009*\"network\" + 0.009*\"python\"\n",
      "0.020*\"course\" + 0.019*\"data\" + 0.016*\"learning\" + 0.011*\"show\" + 0.010*\"r\" + 0.008*\"machine\" + 0.007*\"python\" + 0.007*\"learn\" + 0.007*\"model\" + 0.006*\"using\"\n"
     ]
    }
   ],
   "source": [
    "for i in  range(5):\n",
    "    print(lda.print_topic(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words={}\n",
    "for i in range(lda.num_topics):\n",
    "    topic_words[i]=[dictionary[j] for (j, val) in lda.get_topic_terms(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning</td>\n",
       "      <td>data</td>\n",
       "      <td>learning</td>\n",
       "      <td>course</td>\n",
       "      <td>course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>course</td>\n",
       "      <td>course</td>\n",
       "      <td>data</td>\n",
       "      <td>data</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>machine</td>\n",
       "      <td>machine</td>\n",
       "      <td>course</td>\n",
       "      <td>learning</td>\n",
       "      <td>learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data</td>\n",
       "      <td>learning</td>\n",
       "      <td>machine</td>\n",
       "      <td>show</td>\n",
       "      <td>show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>science</td>\n",
       "      <td>show</td>\n",
       "      <td>science</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>learn</td>\n",
       "      <td>show</td>\n",
       "      <td>learn</td>\n",
       "      <td>learn</td>\n",
       "      <td>machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>show</td>\n",
       "      <td>model</td>\n",
       "      <td>science</td>\n",
       "      <td>deep</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>using</td>\n",
       "      <td>learn</td>\n",
       "      <td>r</td>\n",
       "      <td>machine</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>algorithm</td>\n",
       "      <td>r</td>\n",
       "      <td>deep</td>\n",
       "      <td>network</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>analysis</td>\n",
       "      <td>using</td>\n",
       "      <td>ai</td>\n",
       "      <td>python</td>\n",
       "      <td>using</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   learning      data  learning    course    course\n",
       "1     course    course      data      data      data\n",
       "2    machine   machine    course  learning  learning\n",
       "3       data  learning   machine      show      show\n",
       "4     python   science      show   science         r\n",
       "5      learn      show     learn     learn   machine\n",
       "6       show     model   science      deep    python\n",
       "7      using     learn         r   machine     learn\n",
       "8  algorithm         r      deep   network     model\n",
       "9   analysis     using        ai    python     using"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As we can see above, most of the topic's have common keywords and that is why I am not able to make sense of topics. In the future we can add other courses like software development, finance and then try to implement topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Scope :\n",
    "\n",
    "## -Use SpaCy's inbuilt similarity score function and vectorizer to see if it performs better than TF-IDF and sklearn cosine similarity.\n",
    "\n",
    "## -Try to improve the topics in topic modelling and use it along with Similarity scores.\n",
    "\n",
    "## -Scrape data from other disciplines like business, finance, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion :\n",
    "## <p> We were able to web scrape data science courses from Udemy and clean the description's of courses and implement Cosine similarity which resulted in a very good and meaningful Recommendation system as we saw in the results above.</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
