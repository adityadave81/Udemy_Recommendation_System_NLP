{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "wn=nltk.WordNetLemmatizer()\n",
    "st=nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    s = re.sub(r'Description ', '',text) \n",
    "    s = re.sub(r' show more', '',s).strip().lower()\n",
    "    text=re.sub(r'[^\\w\\s]',' ',s).lower()   ### Remove punctuation by removing non-space alpha-num characters\n",
    "    words=re.split(r'\\W+', text) ### Split by remaining non-alphanumeric characters\n",
    "    non_stop_words=[word for word in words if word not in stopword]        ### Remove stopwords\n",
    "    lem_words= [wn.lemmatize(word) for word in non_stop_words]             ### Clean text ==\n",
    "    clean_text= ' '.join(lem_words)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "files = []\n",
    "for infile in sorted(glob.glob('*_info.txt'), key=numericalSort):\n",
    "    files.append(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1_info.txt',\n",
       " '2_info.txt',\n",
       " '3_info.txt',\n",
       " '4_info.txt',\n",
       " '5_info.txt',\n",
       " '6_info.txt',\n",
       " '7_info.txt',\n",
       " '8_info.txt',\n",
       " '9_info.txt',\n",
       " '10_info.txt',\n",
       " '11_info.txt',\n",
       " '12_info.txt',\n",
       " '13_info.txt',\n",
       " '14_info.txt',\n",
       " '15_info.txt',\n",
       " '16_info.txt',\n",
       " '17_info.txt',\n",
       " '18_info.txt',\n",
       " '19_info.txt',\n",
       " '20_info.txt',\n",
       " '21_info.txt',\n",
       " '22_info.txt',\n",
       " '23_info.txt',\n",
       " '24_info.txt',\n",
       " '25_info.txt',\n",
       " '26_info.txt',\n",
       " '27_info.txt',\n",
       " '28_info.txt',\n",
       " '29_info.txt',\n",
       " '30_info.txt',\n",
       " '31_info.txt',\n",
       " '32_info.txt',\n",
       " '33_info.txt',\n",
       " '34_info.txt',\n",
       " '35_info.txt',\n",
       " '36_info.txt',\n",
       " '37_info.txt',\n",
       " '38_info.txt',\n",
       " '39_info.txt',\n",
       " '40_info.txt',\n",
       " '41_info.txt',\n",
       " '42_info.txt',\n",
       " '43_info.txt',\n",
       " '44_info.txt',\n",
       " '45_info.txt',\n",
       " '46_info.txt',\n",
       " '47_info.txt',\n",
       " '48_info.txt',\n",
       " '49_info.txt',\n",
       " '50_info.txt',\n",
       " '51_info.txt',\n",
       " '52_info.txt',\n",
       " '53_info.txt',\n",
       " '54_info.txt',\n",
       " '55_info.txt',\n",
       " '56_info.txt',\n",
       " '57_info.txt',\n",
       " '58_info.txt',\n",
       " '59_info.txt',\n",
       " '60_info.txt',\n",
       " '61_info.txt',\n",
       " '62_info.txt',\n",
       " '63_info.txt',\n",
       " '64_info.txt',\n",
       " '65_info.txt',\n",
       " '66_info.txt',\n",
       " '67_info.txt',\n",
       " '68_info.txt',\n",
       " '69_info.txt',\n",
       " '70_info.txt',\n",
       " '71_info.txt',\n",
       " '72_info.txt',\n",
       " '73_info.txt',\n",
       " '74_info.txt',\n",
       " '75_info.txt',\n",
       " '76_info.txt',\n",
       " '77_info.txt',\n",
       " '78_info.txt',\n",
       " '79_info.txt',\n",
       " '80_info.txt',\n",
       " '81_info.txt',\n",
       " '82_info.txt',\n",
       " '83_info.txt',\n",
       " '84_info.txt',\n",
       " '85_info.txt',\n",
       " '86_info.txt',\n",
       " '87_info.txt',\n",
       " '88_info.txt',\n",
       " '89_info.txt',\n",
       " '90_info.txt',\n",
       " '91_info.txt',\n",
       " '92_info.txt',\n",
       " '93_info.txt',\n",
       " '94_info.txt',\n",
       " '95_info.txt',\n",
       " '96_info.txt',\n",
       " '97_info.txt',\n",
       " '98_info.txt',\n",
       " '99_info.txt',\n",
       " '100_info.txt',\n",
       " '101_info.txt',\n",
       " '102_info.txt',\n",
       " '103_info.txt',\n",
       " '104_info.txt',\n",
       " '105_info.txt',\n",
       " '106_info.txt',\n",
       " '107_info.txt',\n",
       " '108_info.txt',\n",
       " '109_info.txt',\n",
       " '110_info.txt',\n",
       " '111_info.txt',\n",
       " '112_info.txt',\n",
       " '113_info.txt',\n",
       " '114_info.txt',\n",
       " '115_info.txt',\n",
       " '116_info.txt',\n",
       " '117_info.txt',\n",
       " '118_info.txt',\n",
       " '119_info.txt',\n",
       " '120_info.txt',\n",
       " '121_info.txt',\n",
       " '122_info.txt',\n",
       " '123_info.txt',\n",
       " '124_info.txt',\n",
       " '125_info.txt',\n",
       " '126_info.txt',\n",
       " '127_info.txt',\n",
       " '128_info.txt',\n",
       " '129_info.txt',\n",
       " '130_info.txt',\n",
       " '131_info.txt',\n",
       " '132_info.txt',\n",
       " '133_info.txt',\n",
       " '134_info.txt',\n",
       " '135_info.txt',\n",
       " '136_info.txt',\n",
       " '137_info.txt',\n",
       " '138_info.txt',\n",
       " '139_info.txt',\n",
       " '140_info.txt',\n",
       " '141_info.txt',\n",
       " '142_info.txt',\n",
       " '143_info.txt',\n",
       " '144_info.txt',\n",
       " '145_info.txt',\n",
       " '146_info.txt',\n",
       " '147_info.txt',\n",
       " '148_info.txt',\n",
       " '149_info.txt',\n",
       " '150_info.txt',\n",
       " '151_info.txt',\n",
       " '152_info.txt',\n",
       " '153_info.txt',\n",
       " '154_info.txt',\n",
       " '155_info.txt',\n",
       " '156_info.txt',\n",
       " '157_info.txt',\n",
       " '158_info.txt',\n",
       " '159_info.txt',\n",
       " '160_info.txt',\n",
       " '161_info.txt',\n",
       " '162_info.txt',\n",
       " '163_info.txt',\n",
       " '164_info.txt',\n",
       " '165_info.txt',\n",
       " '166_info.txt',\n",
       " '167_info.txt',\n",
       " '168_info.txt',\n",
       " '169_info.txt',\n",
       " '170_info.txt',\n",
       " '171_info.txt',\n",
       " '172_info.txt',\n",
       " '173_info.txt',\n",
       " '174_info.txt',\n",
       " '175_info.txt',\n",
       " '176_info.txt',\n",
       " '177_info.txt',\n",
       " '178_info.txt',\n",
       " '179_info.txt',\n",
       " '180_info.txt',\n",
       " '181_info.txt',\n",
       " '182_info.txt',\n",
       " '183_info.txt',\n",
       " '184_info.txt',\n",
       " '185_info.txt',\n",
       " '186_info.txt',\n",
       " '187_info.txt',\n",
       " '188_info.txt',\n",
       " '189_info.txt',\n",
       " '190_info.txt',\n",
       " '191_info.txt',\n",
       " '192_info.txt',\n",
       " '193_info.txt',\n",
       " '194_info.txt',\n",
       " '195_info.txt',\n",
       " '196_info.txt',\n",
       " '197_info.txt',\n",
       " '198_info.txt',\n",
       " '199_info.txt',\n",
       " '200_info.txt',\n",
       " '201_info.txt',\n",
       " '202_info.txt',\n",
       " '203_info.txt',\n",
       " '204_info.txt',\n",
       " '205_info.txt',\n",
       " '206_info.txt',\n",
       " '207_info.txt',\n",
       " '208_info.txt',\n",
       " '209_info.txt',\n",
       " '210_info.txt',\n",
       " '211_info.txt',\n",
       " '212_info.txt',\n",
       " '213_info.txt',\n",
       " '214_info.txt',\n",
       " '215_info.txt',\n",
       " '216_info.txt',\n",
       " '217_info.txt',\n",
       " '218_info.txt',\n",
       " '219_info.txt',\n",
       " '220_info.txt',\n",
       " '221_info.txt',\n",
       " '222_info.txt',\n",
       " '223_info.txt',\n",
       " '224_info.txt',\n",
       " '225_info.txt',\n",
       " '226_info.txt',\n",
       " '227_info.txt',\n",
       " '228_info.txt',\n",
       " '229_info.txt',\n",
       " '230_info.txt',\n",
       " '231_info.txt',\n",
       " '232_info.txt',\n",
       " '233_info.txt',\n",
       " '234_info.txt',\n",
       " '235_info.txt',\n",
       " '236_info.txt',\n",
       " '237_info.txt',\n",
       " '238_info.txt',\n",
       " '239_info.txt',\n",
       " '240_info.txt',\n",
       " '241_info.txt',\n",
       " '242_info.txt',\n",
       " '243_info.txt',\n",
       " '244_info.txt',\n",
       " '245_info.txt',\n",
       " '246_info.txt',\n",
       " '247_info.txt',\n",
       " '248_info.txt',\n",
       " '249_info.txt',\n",
       " '250_info.txt',\n",
       " '251_info.txt',\n",
       " '252_info.txt',\n",
       " '253_info.txt',\n",
       " '254_info.txt',\n",
       " '255_info.txt',\n",
       " '256_info.txt',\n",
       " '257_info.txt',\n",
       " '258_info.txt',\n",
       " '259_info.txt',\n",
       " '260_info.txt',\n",
       " '261_info.txt',\n",
       " '262_info.txt',\n",
       " '263_info.txt',\n",
       " '264_info.txt',\n",
       " '265_info.txt',\n",
       " '266_info.txt',\n",
       " '267_info.txt',\n",
       " '268_info.txt',\n",
       " '269_info.txt',\n",
       " '270_info.txt',\n",
       " '271_info.txt',\n",
       " '272_info.txt',\n",
       " '273_info.txt',\n",
       " '274_info.txt',\n",
       " '275_info.txt',\n",
       " '276_info.txt',\n",
       " '277_info.txt',\n",
       " '278_info.txt',\n",
       " '279_info.txt',\n",
       " '280_info.txt',\n",
       " '281_info.txt',\n",
       " '282_info.txt',\n",
       " '283_info.txt',\n",
       " '284_info.txt',\n",
       " '285_info.txt',\n",
       " '286_info.txt',\n",
       " '287_info.txt',\n",
       " '288_info.txt',\n",
       " '289_info.txt',\n",
       " '290_info.txt',\n",
       " '291_info.txt',\n",
       " '292_info.txt',\n",
       " '293_info.txt',\n",
       " '294_info.txt',\n",
       " '295_info.txt',\n",
       " '296_info.txt',\n",
       " '297_info.txt',\n",
       " '298_info.txt',\n",
       " '299_info.txt',\n",
       " '300_info.txt',\n",
       " '301_info.txt',\n",
       " '302_info.txt',\n",
       " '303_info.txt',\n",
       " '304_info.txt',\n",
       " '305_info.txt',\n",
       " '306_info.txt',\n",
       " '307_info.txt',\n",
       " '308_info.txt',\n",
       " '309_info.txt',\n",
       " '310_info.txt',\n",
       " '311_info.txt',\n",
       " '312_info.txt',\n",
       " '313_info.txt',\n",
       " '314_info.txt',\n",
       " '315_info.txt',\n",
       " '316_info.txt',\n",
       " '317_info.txt',\n",
       " '318_info.txt',\n",
       " '319_info.txt',\n",
       " '320_info.txt',\n",
       " '321_info.txt',\n",
       " '322_info.txt',\n",
       " '323_info.txt',\n",
       " '324_info.txt',\n",
       " '325_info.txt',\n",
       " '326_info.txt',\n",
       " '327_info.txt',\n",
       " '328_info.txt',\n",
       " '329_info.txt',\n",
       " '330_info.txt',\n",
       " '331_info.txt',\n",
       " '332_info.txt',\n",
       " '333_info.txt',\n",
       " '334_info.txt',\n",
       " '335_info.txt',\n",
       " '336_info.txt',\n",
       " '337_info.txt',\n",
       " '338_info.txt',\n",
       " '339_info.txt',\n",
       " '340_info.txt',\n",
       " '341_info.txt',\n",
       " '342_info.txt',\n",
       " '343_info.txt',\n",
       " '344_info.txt',\n",
       " '345_info.txt',\n",
       " '346_info.txt',\n",
       " '347_info.txt',\n",
       " '348_info.txt',\n",
       " '349_info.txt',\n",
       " '350_info.txt',\n",
       " '351_info.txt',\n",
       " '352_info.txt',\n",
       " '353_info.txt',\n",
       " '354_info.txt',\n",
       " '355_info.txt',\n",
       " '356_info.txt',\n",
       " '357_info.txt',\n",
       " '358_info.txt',\n",
       " '359_info.txt',\n",
       " '360_info.txt',\n",
       " '361_info.txt',\n",
       " '362_info.txt',\n",
       " '363_info.txt',\n",
       " '364_info.txt',\n",
       " '365_info.txt',\n",
       " '366_info.txt',\n",
       " '367_info.txt',\n",
       " '368_info.txt',\n",
       " '369_info.txt',\n",
       " '370_info.txt',\n",
       " '371_info.txt',\n",
       " '372_info.txt',\n",
       " '373_info.txt',\n",
       " '374_info.txt',\n",
       " '375_info.txt',\n",
       " '376_info.txt',\n",
       " '377_info.txt',\n",
       " '378_info.txt',\n",
       " '379_info.txt',\n",
       " '380_info.txt',\n",
       " '381_info.txt',\n",
       " '382_info.txt',\n",
       " '383_info.txt',\n",
       " '384_info.txt',\n",
       " '385_info.txt',\n",
       " '386_info.txt',\n",
       " '387_info.txt',\n",
       " '388_info.txt',\n",
       " '389_info.txt',\n",
       " '390_info.txt',\n",
       " '391_info.txt',\n",
       " '392_info.txt',\n",
       " '393_info.txt',\n",
       " '394_info.txt',\n",
       " '395_info.txt',\n",
       " '396_info.txt',\n",
       " '397_info.txt',\n",
       " '398_info.txt',\n",
       " '399_info.txt',\n",
       " '400_info.txt',\n",
       " '401_info.txt',\n",
       " '402_info.txt',\n",
       " '403_info.txt',\n",
       " '404_info.txt',\n",
       " '405_info.txt',\n",
       " '406_info.txt',\n",
       " '407_info.txt',\n",
       " '408_info.txt',\n",
       " '409_info.txt',\n",
       " '410_info.txt',\n",
       " '411_info.txt',\n",
       " '412_info.txt',\n",
       " '413_info.txt',\n",
       " '414_info.txt',\n",
       " '415_info.txt',\n",
       " '416_info.txt',\n",
       " '417_info.txt',\n",
       " '418_info.txt',\n",
       " '419_info.txt',\n",
       " '420_info.txt',\n",
       " '421_info.txt',\n",
       " '422_info.txt',\n",
       " '423_info.txt',\n",
       " '424_info.txt',\n",
       " '425_info.txt',\n",
       " '426_info.txt',\n",
       " '427_info.txt',\n",
       " '428_info.txt',\n",
       " '429_info.txt',\n",
       " '430_info.txt',\n",
       " '431_info.txt',\n",
       " '432_info.txt',\n",
       " '433_info.txt',\n",
       " '434_info.txt',\n",
       " '435_info.txt',\n",
       " '436_info.txt',\n",
       " '437_info.txt',\n",
       " '438_info.txt',\n",
       " '439_info.txt',\n",
       " '440_info.txt',\n",
       " '441_info.txt',\n",
       " '442_info.txt',\n",
       " '443_info.txt',\n",
       " '444_info.txt',\n",
       " '445_info.txt',\n",
       " '446_info.txt',\n",
       " '447_info.txt',\n",
       " '449_info.txt',\n",
       " '450_info.txt',\n",
       " '451_info.txt',\n",
       " '452_info.txt',\n",
       " '453_info.txt',\n",
       " '454_info.txt',\n",
       " '455_info.txt',\n",
       " '456_info.txt',\n",
       " '457_info.txt',\n",
       " '458_info.txt',\n",
       " '459_info.txt',\n",
       " '460_info.txt',\n",
       " '461_info.txt',\n",
       " '462_info.txt',\n",
       " '463_info.txt',\n",
       " '464_info.txt',\n",
       " '465_info.txt',\n",
       " '466_info.txt',\n",
       " '467_info.txt',\n",
       " '468_info.txt',\n",
       " '469_info.txt',\n",
       " '470_info.txt',\n",
       " '471_info.txt',\n",
       " '472_info.txt',\n",
       " '473_info.txt',\n",
       " '474_info.txt',\n",
       " '475_info.txt',\n",
       " '476_info.txt',\n",
       " '477_info.txt',\n",
       " '478_info.txt',\n",
       " '479_info.txt',\n",
       " '480_info.txt',\n",
       " '481_info.txt',\n",
       " '482_info.txt',\n",
       " '483_info.txt',\n",
       " '484_info.txt',\n",
       " '485_info.txt',\n",
       " '486_info.txt',\n",
       " '487_info.txt',\n",
       " '488_info.txt',\n",
       " '489_info.txt',\n",
       " '490_info.txt',\n",
       " '491_info.txt',\n",
       " '492_info.txt',\n",
       " '493_info.txt',\n",
       " '494_info.txt',\n",
       " '495_info.txt',\n",
       " '496_info.txt',\n",
       " '497_info.txt',\n",
       " '498_info.txt',\n",
       " '499_info.txt',\n",
       " '500_info.txt',\n",
       " '501_info.txt',\n",
       " '502_info.txt',\n",
       " '503_info.txt',\n",
       " '504_info.txt',\n",
       " '505_info.txt',\n",
       " '506_info.txt',\n",
       " '507_info.txt',\n",
       " '508_info.txt',\n",
       " '509_info.txt',\n",
       " '510_info.txt',\n",
       " '511_info.txt',\n",
       " '512_info.txt',\n",
       " '513_info.txt',\n",
       " '514_info.txt',\n",
       " '515_info.txt',\n",
       " '516_info.txt',\n",
       " '517_info.txt',\n",
       " '518_info.txt',\n",
       " '519_info.txt',\n",
       " '520_info.txt',\n",
       " '521_info.txt',\n",
       " '522_info.txt',\n",
       " '523_info.txt',\n",
       " '524_info.txt',\n",
       " '525_info.txt',\n",
       " '526_info.txt',\n",
       " '527_info.txt',\n",
       " '528_info.txt',\n",
       " '529_info.txt',\n",
       " '530_info.txt',\n",
       " '531_info.txt',\n",
       " '532_info.txt',\n",
       " '533_info.txt',\n",
       " '534_info.txt',\n",
       " '535_info.txt',\n",
       " '536_info.txt',\n",
       " '537_info.txt',\n",
       " '538_info.txt',\n",
       " '539_info.txt',\n",
       " '540_info.txt',\n",
       " '541_info.txt',\n",
       " '542_info.txt',\n",
       " '543_info.txt',\n",
       " '544_info.txt',\n",
       " '545_info.txt',\n",
       " '546_info.txt',\n",
       " '547_info.txt',\n",
       " '548_info.txt',\n",
       " '549_info.txt',\n",
       " '550_info.txt',\n",
       " '551_info.txt',\n",
       " '552_info.txt',\n",
       " '553_info.txt',\n",
       " '554_info.txt',\n",
       " '555_info.txt',\n",
       " '556_info.txt',\n",
       " '557_info.txt',\n",
       " '558_info.txt',\n",
       " '559_info.txt',\n",
       " '560_info.txt',\n",
       " '561_info.txt',\n",
       " '562_info.txt',\n",
       " '563_info.txt',\n",
       " '564_info.txt',\n",
       " '565_info.txt',\n",
       " '566_info.txt',\n",
       " '567_info.txt',\n",
       " '568_info.txt',\n",
       " '569_info.txt',\n",
       " '570_info.txt',\n",
       " '571_info.txt',\n",
       " '572_info.txt',\n",
       " '573_info.txt',\n",
       " '574_info.txt',\n",
       " '575_info.txt',\n",
       " '576_info.txt',\n",
       " '577_info.txt',\n",
       " '578_info.txt',\n",
       " '579_info.txt',\n",
       " '580_info.txt',\n",
       " '581_info.txt',\n",
       " '582_info.txt',\n",
       " '583_info.txt',\n",
       " '584_info.txt',\n",
       " '585_info.txt',\n",
       " '586_info.txt',\n",
       " '587_info.txt',\n",
       " '589_info.txt',\n",
       " '590_info.txt',\n",
       " '591_info.txt',\n",
       " '592_info.txt',\n",
       " '593_info.txt',\n",
       " '594_info.txt',\n",
       " '595_info.txt',\n",
       " '596_info.txt',\n",
       " '597_info.txt',\n",
       " '598_info.txt',\n",
       " '599_info.txt',\n",
       " '600_info.txt',\n",
       " '601_info.txt',\n",
       " '602_info.txt',\n",
       " '603_info.txt',\n",
       " '604_info.txt',\n",
       " '605_info.txt',\n",
       " '606_info.txt',\n",
       " '607_info.txt',\n",
       " '608_info.txt',\n",
       " '609_info.txt',\n",
       " '610_info.txt',\n",
       " '611_info.txt',\n",
       " '612_info.txt',\n",
       " '613_info.txt',\n",
       " '614_info.txt',\n",
       " '615_info.txt',\n",
       " '616_info.txt',\n",
       " '617_info.txt',\n",
       " '618_info.txt',\n",
       " '619_info.txt',\n",
       " '620_info.txt',\n",
       " '621_info.txt',\n",
       " '622_info.txt',\n",
       " '623_info.txt',\n",
       " '624_info.txt',\n",
       " '625_info.txt',\n",
       " '626_info.txt',\n",
       " '627_info.txt',\n",
       " '628_info.txt',\n",
       " '630_info.txt',\n",
       " '631_info.txt',\n",
       " '632_info.txt',\n",
       " '633_info.txt',\n",
       " '634_info.txt',\n",
       " '635_info.txt',\n",
       " '636_info.txt',\n",
       " '637_info.txt',\n",
       " '638_info.txt',\n",
       " '639_info.txt',\n",
       " '640_info.txt',\n",
       " '641_info.txt',\n",
       " '642_info.txt',\n",
       " '643_info.txt',\n",
       " '644_info.txt',\n",
       " '645_info.txt',\n",
       " '646_info.txt',\n",
       " '647_info.txt',\n",
       " '648_info.txt',\n",
       " '649_info.txt',\n",
       " '650_info.txt',\n",
       " '651_info.txt',\n",
       " '652_info.txt',\n",
       " '653_info.txt',\n",
       " '654_info.txt',\n",
       " '655_info.txt',\n",
       " '656_info.txt',\n",
       " '657_info.txt',\n",
       " '658_info.txt',\n",
       " '659_info.txt',\n",
       " '660_info.txt',\n",
       " '661_info.txt',\n",
       " '662_info.txt',\n",
       " '663_info.txt',\n",
       " '664_info.txt',\n",
       " '665_info.txt',\n",
       " '666_info.txt',\n",
       " '667_info.txt',\n",
       " '668_info.txt',\n",
       " '669_info.txt',\n",
       " '670_info.txt',\n",
       " '671_info.txt',\n",
       " '672_info.txt',\n",
       " '673_info.txt',\n",
       " '674_info.txt',\n",
       " '675_info.txt',\n",
       " '676_info.txt',\n",
       " '677_info.txt',\n",
       " '678_info.txt',\n",
       " '679_info.txt',\n",
       " '680_info.txt',\n",
       " '681_info.txt',\n",
       " '682_info.txt',\n",
       " '683_info.txt',\n",
       " '684_info.txt',\n",
       " '685_info.txt',\n",
       " '686_info.txt',\n",
       " '687_info.txt',\n",
       " '688_info.txt',\n",
       " '689_info.txt',\n",
       " '690_info.txt',\n",
       " '691_info.txt',\n",
       " '692_info.txt',\n",
       " '693_info.txt',\n",
       " '694_info.txt',\n",
       " '695_info.txt',\n",
       " '696_info.txt',\n",
       " '697_info.txt',\n",
       " '698_info.txt',\n",
       " '699_info.txt',\n",
       " '700_info.txt',\n",
       " '701_info.txt',\n",
       " '702_info.txt',\n",
       " '703_info.txt',\n",
       " '704_info.txt',\n",
       " '705_info.txt',\n",
       " '706_info.txt',\n",
       " '707_info.txt',\n",
       " '708_info.txt',\n",
       " '709_info.txt',\n",
       " '710_info.txt',\n",
       " '711_info.txt',\n",
       " '712_info.txt',\n",
       " '713_info.txt',\n",
       " '714_info.txt',\n",
       " '715_info.txt',\n",
       " '716_info.txt',\n",
       " '717_info.txt',\n",
       " '718_info.txt',\n",
       " '719_info.txt',\n",
       " '720_info.txt',\n",
       " '721_info.txt',\n",
       " '722_info.txt',\n",
       " '723_info.txt',\n",
       " '724_info.txt',\n",
       " '725_info.txt',\n",
       " '726_info.txt',\n",
       " '727_info.txt',\n",
       " '728_info.txt',\n",
       " '729_info.txt',\n",
       " '730_info.txt',\n",
       " '731_info.txt',\n",
       " '732_info.txt',\n",
       " '733_info.txt',\n",
       " '734_info.txt',\n",
       " '735_info.txt',\n",
       " '736_info.txt',\n",
       " '737_info.txt',\n",
       " '738_info.txt',\n",
       " '739_info.txt',\n",
       " '740_info.txt',\n",
       " '741_info.txt',\n",
       " '742_info.txt',\n",
       " '743_info.txt',\n",
       " '744_info.txt',\n",
       " '745_info.txt',\n",
       " '746_info.txt',\n",
       " '747_info.txt',\n",
       " '748_info.txt',\n",
       " '749_info.txt',\n",
       " '750_info.txt',\n",
       " '751_info.txt',\n",
       " '752_info.txt',\n",
       " '753_info.txt',\n",
       " '754_info.txt',\n",
       " '755_info.txt',\n",
       " '756_info.txt',\n",
       " '757_info.txt',\n",
       " '758_info.txt',\n",
       " '759_info.txt',\n",
       " '760_info.txt',\n",
       " '761_info.txt',\n",
       " '762_info.txt',\n",
       " '763_info.txt',\n",
       " '764_info.txt',\n",
       " '765_info.txt',\n",
       " '766_info.txt',\n",
       " '767_info.txt',\n",
       " '768_info.txt',\n",
       " '769_info.txt',\n",
       " '770_info.txt',\n",
       " '771_info.txt',\n",
       " '772_info.txt',\n",
       " '773_info.txt',\n",
       " '774_info.txt',\n",
       " '775_info.txt',\n",
       " '776_info.txt',\n",
       " '777_info.txt',\n",
       " '778_info.txt',\n",
       " '779_info.txt',\n",
       " '780_info.txt',\n",
       " '781_info.txt',\n",
       " '782_info.txt',\n",
       " '783_info.txt',\n",
       " '784_info.txt',\n",
       " '785_info.txt',\n",
       " '786_info.txt',\n",
       " '787_info.txt',\n",
       " '788_info.txt',\n",
       " '789_info.txt',\n",
       " '790_info.txt',\n",
       " '791_info.txt',\n",
       " '792_info.txt',\n",
       " '793_info.txt',\n",
       " '794_info.txt',\n",
       " '795_info.txt',\n",
       " '796_info.txt',\n",
       " '797_info.txt',\n",
       " '798_info.txt',\n",
       " '799_info.txt',\n",
       " '800_info.txt',\n",
       " '801_info.txt',\n",
       " '802_info.txt',\n",
       " '803_info.txt',\n",
       " '804_info.txt',\n",
       " '805_info.txt',\n",
       " '806_info.txt',\n",
       " '807_info.txt',\n",
       " '808_info.txt',\n",
       " '809_info.txt',\n",
       " '810_info.txt',\n",
       " '811_info.txt',\n",
       " '812_info.txt',\n",
       " '813_info.txt',\n",
       " '814_info.txt',\n",
       " '815_info.txt',\n",
       " '816_info.txt',\n",
       " '817_info.txt',\n",
       " '818_info.txt',\n",
       " '819_info.txt',\n",
       " '820_info.txt',\n",
       " '821_info.txt',\n",
       " '822_info.txt',\n",
       " '823_info.txt',\n",
       " '824_info.txt',\n",
       " '825_info.txt',\n",
       " '826_info.txt',\n",
       " '827_info.txt',\n",
       " '828_info.txt',\n",
       " '829_info.txt',\n",
       " '830_info.txt',\n",
       " '831_info.txt',\n",
       " '832_info.txt',\n",
       " '833_info.txt',\n",
       " '834_info.txt',\n",
       " '835_info.txt',\n",
       " '836_info.txt',\n",
       " '837_info.txt',\n",
       " '838_info.txt',\n",
       " '839_info.txt',\n",
       " '840_info.txt',\n",
       " '841_info.txt',\n",
       " '842_info.txt',\n",
       " '843_info.txt',\n",
       " '844_info.txt',\n",
       " '845_info.txt',\n",
       " '846_info.txt',\n",
       " '847_info.txt',\n",
       " '848_info.txt',\n",
       " '849_info.txt',\n",
       " '850_info.txt',\n",
       " '851_info.txt',\n",
       " '852_info.txt',\n",
       " '853_info.txt',\n",
       " '854_info.txt',\n",
       " '855_info.txt',\n",
       " '856_info.txt',\n",
       " '857_info.txt',\n",
       " '858_info.txt',\n",
       " '859_info.txt',\n",
       " '860_info.txt',\n",
       " '861_info.txt',\n",
       " '862_info.txt',\n",
       " '863_info.txt',\n",
       " '864_info.txt',\n",
       " '865_info.txt',\n",
       " '866_info.txt',\n",
       " '867_info.txt',\n",
       " '868_info.txt',\n",
       " '869_info.txt',\n",
       " '870_info.txt',\n",
       " '871_info.txt',\n",
       " '872_info.txt',\n",
       " '873_info.txt',\n",
       " '874_info.txt',\n",
       " '875_info.txt',\n",
       " '876_info.txt',\n",
       " '877_info.txt',\n",
       " '878_info.txt',\n",
       " '879_info.txt',\n",
       " '880_info.txt',\n",
       " '881_info.txt',\n",
       " '882_info.txt',\n",
       " '883_info.txt',\n",
       " '884_info.txt',\n",
       " '885_info.txt',\n",
       " '886_info.txt',\n",
       " '887_info.txt',\n",
       " '888_info.txt',\n",
       " '889_info.txt',\n",
       " '890_info.txt',\n",
       " '891_info.txt',\n",
       " '892_info.txt',\n",
       " '893_info.txt',\n",
       " '894_info.txt',\n",
       " '895_info.txt',\n",
       " '896_info.txt',\n",
       " '897_info.txt',\n",
       " '898_info.txt',\n",
       " '899_info.txt',\n",
       " '900_info.txt',\n",
       " '901_info.txt',\n",
       " '902_info.txt',\n",
       " '903_info.txt',\n",
       " '904_info.txt',\n",
       " '905_info.txt',\n",
       " '906_info.txt',\n",
       " '907_info.txt',\n",
       " '908_info.txt',\n",
       " '909_info.txt',\n",
       " '910_info.txt',\n",
       " '911_info.txt',\n",
       " '912_info.txt',\n",
       " '913_info.txt',\n",
       " '914_info.txt',\n",
       " '915_info.txt',\n",
       " '916_info.txt',\n",
       " '917_info.txt',\n",
       " '918_info.txt',\n",
       " '919_info.txt',\n",
       " '920_info.txt',\n",
       " '921_info.txt',\n",
       " '922_info.txt',\n",
       " '923_info.txt',\n",
       " '924_info.txt',\n",
       " '925_info.txt',\n",
       " '926_info.txt',\n",
       " '927_info.txt',\n",
       " '928_info.txt',\n",
       " '929_info.txt',\n",
       " '930_info.txt',\n",
       " '931_info.txt',\n",
       " '932_info.txt',\n",
       " '933_info.txt',\n",
       " '934_info.txt',\n",
       " '935_info.txt',\n",
       " '936_info.txt',\n",
       " '937_info.txt',\n",
       " '938_info.txt',\n",
       " '939_info.txt',\n",
       " '940_info.txt',\n",
       " '941_info.txt',\n",
       " '942_info.txt',\n",
       " '943_info.txt',\n",
       " '944_info.txt',\n",
       " '945_info.txt',\n",
       " '946_info.txt',\n",
       " '948_info.txt',\n",
       " '949_info.txt',\n",
       " '950_info.txt',\n",
       " '951_info.txt',\n",
       " '952_info.txt',\n",
       " '953_info.txt',\n",
       " '954_info.txt',\n",
       " '955_info.txt',\n",
       " '956_info.txt',\n",
       " '957_info.txt',\n",
       " '958_info.txt',\n",
       " '959_info.txt',\n",
       " '960_info.txt',\n",
       " '961_info.txt',\n",
       " '962_info.txt',\n",
       " '963_info.txt',\n",
       " '964_info.txt',\n",
       " '965_info.txt',\n",
       " '966_info.txt',\n",
       " '967_info.txt',\n",
       " '968_info.txt',\n",
       " '969_info.txt',\n",
       " '970_info.txt',\n",
       " '971_info.txt',\n",
       " '972_info.txt',\n",
       " '973_info.txt',\n",
       " '974_info.txt',\n",
       " '975_info.txt',\n",
       " '976_info.txt',\n",
       " '977_info.txt',\n",
       " '978_info.txt',\n",
       " '979_info.txt',\n",
       " '980_info.txt',\n",
       " '981_info.txt',\n",
       " '982_info.txt',\n",
       " '983_info.txt',\n",
       " '984_info.txt',\n",
       " '985_info.txt',\n",
       " '986_info.txt',\n",
       " '987_info.txt',\n",
       " '988_info.txt',\n",
       " '989_info.txt',\n",
       " '990_info.txt',\n",
       " '991_info.txt',\n",
       " '992_info.txt',\n",
       " '993_info.txt',\n",
       " '994_info.txt',\n",
       " '995_info.txt',\n",
       " '996_info.txt',\n",
       " '997_info.txt',\n",
       " '998_info.txt',\n",
       " '999_info.txt',\n",
       " '1000_info.txt',\n",
       " '1001_info.txt',\n",
       " '1002_info.txt',\n",
       " '1003_info.txt',\n",
       " '1004_info.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "15 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m         result = _convert_object_array(\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[1;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    581\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 15 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4a4f8820a7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'purpose'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'total_enrollment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rating'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'number_ratings'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'last_update_date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'what_you_get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'prerequisites'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'description'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'five_stars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'four_stars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'three_stars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'two_stars'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'one_star'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# columns if columns is not None else []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    462\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[1;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 15 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "count = 0\n",
    "while count < 1999:\n",
    "    for file in files:\n",
    "        with open(file,'r',encoding=\"utf8\") as f:\n",
    "            data=f.read().split('\\n\\n')\n",
    "            data=[i.split('\\n') for i in data]\n",
    "            s=pd.DataFrame([data[0][0:15]],columns=['id', 'title', 'purpose', 'total_enrollment', 'rating', 'number_ratings', 'last_update_date', 'what_you_get', 'prerequisites', 'description', 'five_stars', 'four_stars', 'three_stars', 'two_stars', 'one_star'])\n",
    "            df = s\n",
    "            df =pd.concat([df, s], ignore_index=True)\n",
    "            count += 1\n",
    "\n",
    "#df = df.iloc[1: , :]\n",
    "#df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description_clean'] = df['description'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:/Users/15512/course_list_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = pd.concat([df, df2[:2001]], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 26)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'purpose', 'total_enrollment', 'rating',\n",
       "       'number_ratings', 'last_update_date', 'what_you_get', 'prerequisites',\n",
       "       'description', 'five_stars', 'four_stars', 'three_stars', 'two_stars',\n",
       "       'one_star', 'description_clean', 'id', 'name', 'link', 'seller',\n",
       "       'price', 'original_price', 'lectures', 'hours', 'level',\n",
       "       'Tue Dec 14 05:56:01 2021'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.drop(complete_data.columns[[4, 5, 16, 17, 25]], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_trans=TfidfVectorizer()\n",
    "X_tfidf=tfidf_trans.fit_transform(complete_data['description_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recommend():\n",
    "    input_string = input('Enter the description of Udemy Course:')\n",
    "    input_string_clean = clean(input_string)\n",
    "    input_string_v = tfidf_trans.transform([input_string_clean])\n",
    "    cosine_simil = cosine_similarity(input_string_v, X_tfidf)[0]\n",
    "    sorted_index= np.argsort(cosine_simil)[::-1]\n",
    "    return pd.DataFrame([complete_data.iloc[i].to_numpy().T for i in sorted_index], columns = complete_data.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the description of Udemy Course:You've definitely heard of AI and Deep Learning. But when you ask yourself, what is my position with respect to this new industrial revolution, that might lead you to another fundamental question: am I a consumer or a creator? For most people nowadays, the answer would be, a consumer.  But what if you could also become a creator?  What if there was a way for you to easily break into the World of Artificial Intelligence and build amazing applications which leverage the latest technology to make the World a better place?  Sounds too good to be true, doesn't it?  But there actually is a way..  Computer Vision is by far the easiest way of becoming a creator.  And it's not only the easiest way, it's also the branch of AI where there is the most to create.  Why? You'll ask.  That's because Computer Vision is applied everywhere. From health to retail to entertainment - the list goes on. Computer Vision is already a $18 Billion market and is growing exponentially.  Just think of tumor detection in patient MRI brain scans. How many more lives are saved every day simply because a computer can analyze 10,000x more images than a human?  And what if you find an industry where Computer Vision is not yet applied? Then all the better! That means there's a business opportunity which you can take advantage of.  So now that raises the question: how do you break into the World of Computer Vision?  Up until now, computer vision has for the most part been a maze. A growing maze.  As the number of codes, libraries and tools in CV grows, it becomes harder and harder to not get lost.  On top of that, not only do you need to know how to use it - you also need to know how it works to maximise the advantage of using Computer Vision.  To this problem we want to bring...   Computer Vision A-Z.  With this brand new course you will not only learn how the most popular computer vision methods work, but you will also learn to apply them in practice!  Can't wait to see you inside the class,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>what_you_get</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>description</th>\n",
       "      <th>five_stars</th>\n",
       "      <th>four_stars</th>\n",
       "      <th>three_stars</th>\n",
       "      <th>two_stars</th>\n",
       "      <th>one_star</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Learning and Computer Vision A Z   OpenCV...</td>\n",
       "      <td>Become a Wizard of all the latest Computer Vis...</td>\n",
       "      <td>43258</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Have a toolbox of the most powerful Computer V...</td>\n",
       "      <td>Requirements Only High School Maths Basic Pyth...</td>\n",
       "      <td>Description *** AS SEEN ON KICKSTARTER *** You...</td>\n",
       "      <td>53%</td>\n",
       "      <td>32%</td>\n",
       "      <td>10%</td>\n",
       "      <td>3%</td>\n",
       "      <td>2%</td>\n",
       "      <td>seen kickstarter definitely heard ai deep lea...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-a-z/</td>\n",
       "      <td>Hadelin de Ponteves  Kirill Eremenko  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>85</td>\n",
       "      <td>11</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computer Vision Masterclass</td>\n",
       "      <td>Learn in practice everything you need to know ...</td>\n",
       "      <td>26710</td>\n",
       "      <td>10/2021</td>\n",
       "      <td>Understand the basic intuition about Cascade a...</td>\n",
       "      <td>Requirements Programming logic Basic Python pr...</td>\n",
       "      <td>Description Computer Vision is a subarea of Ar...</td>\n",
       "      <td>51%</td>\n",
       "      <td>33%</td>\n",
       "      <td>13%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>computer vision subarea artificial intelligenc...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-m...</td>\n",
       "      <td>Jones Granatyr  Ligency I Team  Gabriel Alves</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>228</td>\n",
       "      <td>25.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computer Vision In Python  Face Detection   Im...</td>\n",
       "      <td>Learn Computer Vision With OpenCV In Python! M...</td>\n",
       "      <td>16702</td>\n",
       "      <td>8/2021</td>\n",
       "      <td>Use OpenCV to work with image files Understand...</td>\n",
       "      <td>Requirements Basic Python programming knowledge</td>\n",
       "      <td>Description Computer vision is an interdiscipl...</td>\n",
       "      <td>46%</td>\n",
       "      <td>39%</td>\n",
       "      <td>11%</td>\n",
       "      <td>3%</td>\n",
       "      <td>1%</td>\n",
       "      <td>computer vision interdisciplinary field deal c...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-i...</td>\n",
       "      <td>Emenwa Global  Zoolord Academy</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computer Vision  Face Recognition Quick Starte...</td>\n",
       "      <td>Quickly Build Python Deep Learning based Face ...</td>\n",
       "      <td>3229</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Face Detection from Images Face Detection from...</td>\n",
       "      <td>Requirements A decent configuration computer a...</td>\n",
       "      <td>Description Hi There!  welcome to my new cours...</td>\n",
       "      <td>45%</td>\n",
       "      <td>42%</td>\n",
       "      <td>10%</td>\n",
       "      <td>2%</td>\n",
       "      <td>1%</td>\n",
       "      <td>hi welcome new course face recognition deep le...</td>\n",
       "      <td>https://www.udemy.com/course/computer-vision-f...</td>\n",
       "      <td>Abhilash Nelson</td>\n",
       "      <td>15.99</td>\n",
       "      <td>99.99</td>\n",
       "      <td>64</td>\n",
       "      <td>6.5</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automated Multiple Face Recognition AI Using P...</td>\n",
       "      <td>Learn about OpenCv Basics, Face Recognition in...</td>\n",
       "      <td>19677</td>\n",
       "      <td>11/2019</td>\n",
       "      <td>Automated Multiple Face Recognition in an imag...</td>\n",
       "      <td>Requirements Basics of Python Programming</td>\n",
       "      <td>Description Hello, welcome to the Amazing worl...</td>\n",
       "      <td>27%</td>\n",
       "      <td>31%</td>\n",
       "      <td>27%</td>\n",
       "      <td>9%</td>\n",
       "      <td>6%</td>\n",
       "      <td>hello welcome amazing world computer vision co...</td>\n",
       "      <td>https://www.udemy.com/course/automated-multipl...</td>\n",
       "      <td>Nishit Maru  Three Millennials</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>All Levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Deep Learning and Computer Vision A Z   OpenCV...   \n",
       "1                        Computer Vision Masterclass   \n",
       "2  Computer Vision In Python  Face Detection   Im...   \n",
       "3  Computer Vision  Face Recognition Quick Starte...   \n",
       "4  Automated Multiple Face Recognition AI Using P...   \n",
       "\n",
       "                                             purpose total_enrollment  \\\n",
       "0  Become a Wizard of all the latest Computer Vis...            43258   \n",
       "1  Learn in practice everything you need to know ...            26710   \n",
       "2  Learn Computer Vision With OpenCV In Python! M...            16702   \n",
       "3  Quickly Build Python Deep Learning based Face ...             3229   \n",
       "4  Learn about OpenCv Basics, Face Recognition in...            19677   \n",
       "\n",
       "  last_update_date                                       what_you_get  \\\n",
       "0          12/2021  Have a toolbox of the most powerful Computer V...   \n",
       "1          10/2021  Understand the basic intuition about Cascade a...   \n",
       "2           8/2021  Use OpenCV to work with image files Understand...   \n",
       "3          12/2021  Face Detection from Images Face Detection from...   \n",
       "4          11/2019  Automated Multiple Face Recognition in an imag...   \n",
       "\n",
       "                                       prerequisites  \\\n",
       "0  Requirements Only High School Maths Basic Pyth...   \n",
       "1  Requirements Programming logic Basic Python pr...   \n",
       "2    Requirements Basic Python programming knowledge   \n",
       "3  Requirements A decent configuration computer a...   \n",
       "4          Requirements Basics of Python Programming   \n",
       "\n",
       "                                         description five_stars four_stars  \\\n",
       "0  Description *** AS SEEN ON KICKSTARTER *** You...        53%        32%   \n",
       "1  Description Computer Vision is a subarea of Ar...        51%        33%   \n",
       "2  Description Computer vision is an interdiscipl...        46%        39%   \n",
       "3  Description Hi There!  welcome to my new cours...        45%        42%   \n",
       "4  Description Hello, welcome to the Amazing worl...        27%        31%   \n",
       "\n",
       "  three_stars two_stars one_star  \\\n",
       "0         10%        3%       2%   \n",
       "1         13%        2%       1%   \n",
       "2         11%        3%       1%   \n",
       "3         10%        2%       1%   \n",
       "4         27%        9%       6%   \n",
       "\n",
       "                                   description_clean  \\\n",
       "0   seen kickstarter definitely heard ai deep lea...   \n",
       "1  computer vision subarea artificial intelligenc...   \n",
       "2  computer vision interdisciplinary field deal c...   \n",
       "3  hi welcome new course face recognition deep le...   \n",
       "4  hello welcome amazing world computer vision co...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://www.udemy.com/course/computer-vision-a-z/   \n",
       "1  https://www.udemy.com/course/computer-vision-m...   \n",
       "2  https://www.udemy.com/course/computer-vision-i...   \n",
       "3  https://www.udemy.com/course/computer-vision-f...   \n",
       "4  https://www.udemy.com/course/automated-multipl...   \n",
       "\n",
       "                                              seller  price  original_price  \\\n",
       "0  Hadelin de Ponteves  Kirill Eremenko  Ligency ...  13.99           84.99   \n",
       "1      Jones Granatyr  Ligency I Team  Gabriel Alves  13.99           84.99   \n",
       "2                     Emenwa Global  Zoolord Academy  13.99           84.99   \n",
       "3                                    Abhilash Nelson  15.99           99.99   \n",
       "4                     Nishit Maru  Three Millennials  13.99           84.99   \n",
       "\n",
       "   lectures  hours       level  \n",
       "0        85    11   All Levels  \n",
       "1       228  25.5   All Levels  \n",
       "2        61    11   All Levels  \n",
       "3        64   6.5   All Levels  \n",
       "4        10     2   All Levels  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recommend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('C:/Users/15512/course_list_all.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "      <th>Tue Dec 14 05:56:01 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>machinelearning/</td>\n",
       "      <td>https://www.udemy.com/course/machinelearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>320</td>\n",
       "      <td>44.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>python-for-data-science-and-machine-learning-b...</td>\n",
       "      <td>https://www.udemy.com/course/python-for-data-s...</td>\n",
       "      <td>Jose Portilla</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>165</td>\n",
       "      <td>25</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>the-data-science-course-complete-data-science-...</td>\n",
       "      <td>https://www.udemy.com/course/the-data-science-...</td>\n",
       "      <td>365 Careers  365 Careers Team</td>\n",
       "      <td>15.99</td>\n",
       "      <td>94.99</td>\n",
       "      <td>488</td>\n",
       "      <td>30</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>r-programming/</td>\n",
       "      <td>https://www.udemy.com/course/r-programming/</td>\n",
       "      <td>Kirill Eremenko  Ligency I Team  Ligency Team</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>82</td>\n",
       "      <td>10.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>deeplearning/</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>173</td>\n",
       "      <td>22.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>2188</td>\n",
       "      <td>master-en-machine-learning/</td>\n",
       "      <td>https://www.udemy.com/course/master-en-machine...</td>\n",
       "      <td>Juan Gabriel Gomila Salas  Mar a Santos  Arnau...</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>16.5</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>2189</td>\n",
       "      <td>data-science-foundations/</td>\n",
       "      <td>https://www.udemy.com/course/data-science-foun...</td>\n",
       "      <td>Eng  Mustafa Othman</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>2190</td>\n",
       "      <td>introduccion-gratuita-python-data-science/</td>\n",
       "      <td>https://www.udemy.com/course/introduccion-grat...</td>\n",
       "      <td>Rafael Gonzalez Gouveia</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1 total</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2191</td>\n",
       "      <td>guia-iniciantes-machine-learning-data-science/</td>\n",
       "      <td>https://www.udemy.com/course/guia-iniciantes-m...</td>\n",
       "      <td>Jones Granatyr  IA Expert Academy</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>2192</td>\n",
       "      <td>introduccion-al-data-science/</td>\n",
       "      <td>https://www.udemy.com/course/introduccion-al-d...</td>\n",
       "      <td>Pedro Daniel Alcal  Rojas</td>\n",
       "      <td>Free</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>1.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2192 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               name  \\\n",
       "0        1                                   machinelearning/   \n",
       "1        2  python-for-data-science-and-machine-learning-b...   \n",
       "2        3  the-data-science-course-complete-data-science-...   \n",
       "3        4                                     r-programming/   \n",
       "4        5                                      deeplearning/   \n",
       "...    ...                                                ...   \n",
       "2187  2188                        master-en-machine-learning/   \n",
       "2188  2189                          data-science-foundations/   \n",
       "2189  2190         introduccion-gratuita-python-data-science/   \n",
       "2190  2191     guia-iniciantes-machine-learning-data-science/   \n",
       "2191  2192                      introduccion-al-data-science/   \n",
       "\n",
       "                                                   link  \\\n",
       "0         https://www.udemy.com/course/machinelearning/   \n",
       "1     https://www.udemy.com/course/python-for-data-s...   \n",
       "2     https://www.udemy.com/course/the-data-science-...   \n",
       "3           https://www.udemy.com/course/r-programming/   \n",
       "4            https://www.udemy.com/course/deeplearning/   \n",
       "...                                                 ...   \n",
       "2187  https://www.udemy.com/course/master-en-machine...   \n",
       "2188  https://www.udemy.com/course/data-science-foun...   \n",
       "2189  https://www.udemy.com/course/introduccion-grat...   \n",
       "2190  https://www.udemy.com/course/guia-iniciantes-m...   \n",
       "2191  https://www.udemy.com/course/introduccion-al-d...   \n",
       "\n",
       "                                                 seller  price  \\\n",
       "0     Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99   \n",
       "1                                         Jose Portilla  13.99   \n",
       "2                         365 Careers  365 Careers Team  15.99   \n",
       "3         Kirill Eremenko  Ligency I Team  Ligency Team  13.99   \n",
       "4     Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99   \n",
       "...                                                 ...    ...   \n",
       "2187  Juan Gabriel Gomila Salas  Mar a Santos  Arnau...   Free   \n",
       "2188                                Eng  Mustafa Othman   Free   \n",
       "2189                            Rafael Gonzalez Gouveia   Free   \n",
       "2190                  Jones Granatyr  IA Expert Academy   Free   \n",
       "2191                          Pedro Daniel Alcal  Rojas   Free   \n",
       "\n",
       "      original_price  lectures     hours       level  Tue Dec 14 05:56:01 2021  \n",
       "0              84.99       320     44.5   All Levels                       NaN  \n",
       "1              84.99       165       25   All Levels                       NaN  \n",
       "2              94.99       488       30   All Levels                       NaN  \n",
       "3              84.99        82     10.5   All Levels                       NaN  \n",
       "4              84.99       173     22.5   All Levels                       NaN  \n",
       "...              ...       ...       ...         ...                       ...  \n",
       "2187             NaN        73     16.5     Beginner                       NaN  \n",
       "2188             NaN        11        2     Beginner                       NaN  \n",
       "2189             NaN        13  1 total     Beginner                       NaN  \n",
       "2190             NaN        28        2     Beginner                       NaN  \n",
       "2191             NaN        15      1.5   All Levels                       NaN  \n",
       "\n",
       "[2192 rows x 10 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df123456 = pd.concat([df, df2[:427]], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>purpose</th>\n",
       "      <th>total_enrollment</th>\n",
       "      <th>rating</th>\n",
       "      <th>number_ratings</th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>what_you_get</th>\n",
       "      <th>prerequisites</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>seller</th>\n",
       "      <th>price</th>\n",
       "      <th>original_price</th>\n",
       "      <th>lectures</th>\n",
       "      <th>hours</th>\n",
       "      <th>level</th>\n",
       "      <th>Tue Dec 14 05:56:01 2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning A Z   Hands On Python   R In ...</td>\n",
       "      <td>Learn to create Machine Learning Algorithms in...</td>\n",
       "      <td>833575</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Master Machine Learning on Python   R Have a g...</td>\n",
       "      <td>Requirements Just some high school mathematics...</td>\n",
       "      <td>Description Interested in the field of Machine...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>machinelearning/</td>\n",
       "      <td>https://www.udemy.com/course/machinelearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>320</td>\n",
       "      <td>44.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Python for Data Science and Machine Learning B...</td>\n",
       "      <td>Learn how to use NumPy, Pandas, Seaborn , Matp...</td>\n",
       "      <td>501618</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>5/2020</td>\n",
       "      <td>Use Python for Data Science and Machine Learni...</td>\n",
       "      <td>Requirements Some programming experience Admin...</td>\n",
       "      <td>Description Are you ready to start your path t...</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>python-for-data-science-and-machine-learning-b...</td>\n",
       "      <td>https://www.udemy.com/course/python-for-data-s...</td>\n",
       "      <td>Jose Portilla</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>165</td>\n",
       "      <td>25</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Data Science Course 2021  Complete Data Sc...</td>\n",
       "      <td>Complete Data Science Training: Mathematics, S...</td>\n",
       "      <td>452453</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>11/2021</td>\n",
       "      <td>The course provides the entire toolbox you nee...</td>\n",
       "      <td>Requirements No prior experience is required  ...</td>\n",
       "      <td>Description The Problem Data scientist is one ...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>the-data-science-course-complete-data-science-...</td>\n",
       "      <td>https://www.udemy.com/course/the-data-science-...</td>\n",
       "      <td>365 Careers  365 Careers Team</td>\n",
       "      <td>15.99</td>\n",
       "      <td>94.99</td>\n",
       "      <td>488</td>\n",
       "      <td>30</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>R Programming A Z   R For Data Science With Re...</td>\n",
       "      <td>Learn Programming In R And R Studio. Data Anal...</td>\n",
       "      <td>221022</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Learn to program in R at a good level Learn ho...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description Learn R Programming by doing! Ther...</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>r-programming/</td>\n",
       "      <td>https://www.udemy.com/course/r-programming/</td>\n",
       "      <td>Kirill Eremenko  Ligency I Team  Ligency Team</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>82</td>\n",
       "      <td>10.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Deep Learning A Z   Hands On Artificial Neural...</td>\n",
       "      <td>Learn to create Deep Learning Algorithms in Py...</td>\n",
       "      <td>322765</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>Understand the intuition behind Artificial Neu...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description *** As seen on Kickstarter *** Art...</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>deeplearning/</td>\n",
       "      <td>https://www.udemy.com/course/deeplearning/</td>\n",
       "      <td>Kirill Eremenko  Hadelin de Ponteves  Ligency ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>173</td>\n",
       "      <td>22.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>423</td>\n",
       "      <td>Time Series Analysis and Forecasting with Python</td>\n",
       "      <td>Learn Python for Pandas, Statsmodels, ARIMA, S...</td>\n",
       "      <td>3492</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>8/2021</td>\n",
       "      <td>Basic Packages  NumPy  Pandas   Matplotlib Tim...</td>\n",
       "      <td>Requirements General and Basic Python Skills</td>\n",
       "      <td>Description \"Time Series Analysis and Forecast...</td>\n",
       "      <td>...</td>\n",
       "      <td>423</td>\n",
       "      <td>time-series-analysis-and-forecasting-with-python/</td>\n",
       "      <td>https://www.udemy.com/course/time-series-analy...</td>\n",
       "      <td>Navid Shirzadi</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>51</td>\n",
       "      <td>10.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>424</td>\n",
       "      <td>Artificial Intelligence in Arabic             ...</td>\n",
       "      <td>        </td>\n",
       "      <td>998</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>2/2019</td>\n",
       "      <td>Numpy  pandas  matplotlib  seaborn            ...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description      ...</td>\n",
       "      <td>...</td>\n",
       "      <td>424</td>\n",
       "      <td>artificial-intelligence-in-arabic/</td>\n",
       "      <td>https://www.udemy.com/course/artificial-intell...</td>\n",
       "      <td>Dr  Ryan Ahmed  Ph D   MBA  Mitchell Bouchard ...</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>425</td>\n",
       "      <td>Natural Language Processing  NLP In Python wit...</td>\n",
       "      <td>Learn NLP with Machine Learning Algorithms, Sp...</td>\n",
       "      <td>19672</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>7/2021</td>\n",
       "      <td>Get to learn about different Applications of N...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description Interested in Learning Natural Lan...</td>\n",
       "      <td>...</td>\n",
       "      <td>425</td>\n",
       "      <td>nlp-bootcamp-machine-learning-deep-learning/</td>\n",
       "      <td>https://www.udemy.com/course/nlp-bootcamp-mach...</td>\n",
       "      <td>Data Is Good Academy</td>\n",
       "      <td>13.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>426</td>\n",
       "      <td>100  Exercises   Python Programming   Data Sci...</td>\n",
       "      <td>Improve your Python programming and data scien...</td>\n",
       "      <td>40347</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>12/2021</td>\n",
       "      <td>solve over 100 exercises in NumPy deal with re...</td>\n",
       "      <td>Requirements completed course  200  Exercises ...</td>\n",
       "      <td>Description ----------------------------------...</td>\n",
       "      <td>...</td>\n",
       "      <td>426</td>\n",
       "      <td>100-exercises-python-programming-data-science-...</td>\n",
       "      <td>https://www.udemy.com/course/100-exercises-pyt...</td>\n",
       "      <td>Pawe  Krakowiak  takeITeasy Academy</td>\n",
       "      <td>13.99</td>\n",
       "      <td>19.99</td>\n",
       "      <td>118</td>\n",
       "      <td>1 total</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>427</td>\n",
       "      <td>2022 Python and Machine Learning in Financial ...</td>\n",
       "      <td>Using Python and machine learning in financial...</td>\n",
       "      <td>25904</td>\n",
       "      <td>NULL</td>\n",
       "      <td>NULL</td>\n",
       "      <td>9/2021</td>\n",
       "      <td>You will be able to use the functions provided...</td>\n",
       "      <td>Requirements</td>\n",
       "      <td>Description In this course, you will become fa...</td>\n",
       "      <td>...</td>\n",
       "      <td>427</td>\n",
       "      <td>python-and-machine-learning-in-financial-analy...</td>\n",
       "      <td>https://www.udemy.com/course/python-and-machin...</td>\n",
       "      <td>S Emadedin Hashemi</td>\n",
       "      <td>13.99</td>\n",
       "      <td>84.99</td>\n",
       "      <td>82</td>\n",
       "      <td>20.5</td>\n",
       "      <td>All Levels</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0      1  Machine Learning A Z   Hands On Python   R In ...   \n",
       "1      2  Python for Data Science and Machine Learning B...   \n",
       "2      3  The Data Science Course 2021  Complete Data Sc...   \n",
       "3      4  R Programming A Z   R For Data Science With Re...   \n",
       "4      5  Deep Learning A Z   Hands On Artificial Neural...   \n",
       "..   ...                                                ...   \n",
       "422  423   Time Series Analysis and Forecasting with Python   \n",
       "423  424  Artificial Intelligence in Arabic             ...   \n",
       "424  425  Natural Language Processing  NLP In Python wit...   \n",
       "425  426  100  Exercises   Python Programming   Data Sci...   \n",
       "426  427  2022 Python and Machine Learning in Financial ...   \n",
       "\n",
       "                                               purpose total_enrollment  \\\n",
       "0    Learn to create Machine Learning Algorithms in...           833575   \n",
       "1    Learn how to use NumPy, Pandas, Seaborn , Matp...           501618   \n",
       "2    Complete Data Science Training: Mathematics, S...           452453   \n",
       "3    Learn Programming In R And R Studio. Data Anal...           221022   \n",
       "4    Learn to create Deep Learning Algorithms in Py...           322765   \n",
       "..                                                 ...              ...   \n",
       "422  Learn Python for Pandas, Statsmodels, ARIMA, S...             3492   \n",
       "423                        998   \n",
       "424  Learn NLP with Machine Learning Algorithms, Sp...            19672   \n",
       "425  Improve your Python programming and data scien...            40347   \n",
       "426  Using Python and machine learning in financial...            25904   \n",
       "\n",
       "    rating number_ratings last_update_date  \\\n",
       "0     NULL           NULL          12/2021   \n",
       "1     NULL           NULL           5/2020   \n",
       "2     NULL           NULL          11/2021   \n",
       "3     NULL           NULL          12/2021   \n",
       "4     NULL           NULL          12/2021   \n",
       "..     ...            ...              ...   \n",
       "422   NULL           NULL           8/2021   \n",
       "423   NULL           NULL           2/2019   \n",
       "424   NULL           NULL           7/2021   \n",
       "425   NULL           NULL          12/2021   \n",
       "426   NULL           NULL           9/2021   \n",
       "\n",
       "                                          what_you_get  \\\n",
       "0    Master Machine Learning on Python   R Have a g...   \n",
       "1    Use Python for Data Science and Machine Learni...   \n",
       "2    The course provides the entire toolbox you nee...   \n",
       "3    Learn to program in R at a good level Learn ho...   \n",
       "4    Understand the intuition behind Artificial Neu...   \n",
       "..                                                 ...   \n",
       "422  Basic Packages  NumPy  Pandas   Matplotlib Tim...   \n",
       "423  Numpy  pandas  matplotlib  seaborn            ...   \n",
       "424  Get to learn about different Applications of N...   \n",
       "425  solve over 100 exercises in NumPy deal with re...   \n",
       "426  You will be able to use the functions provided...   \n",
       "\n",
       "                                         prerequisites  \\\n",
       "0    Requirements Just some high school mathematics...   \n",
       "1    Requirements Some programming experience Admin...   \n",
       "2    Requirements No prior experience is required  ...   \n",
       "3                                         Requirements   \n",
       "4                                         Requirements   \n",
       "..                                                 ...   \n",
       "422       Requirements General and Basic Python Skills   \n",
       "423                                       Requirements   \n",
       "424                                       Requirements   \n",
       "425  Requirements completed course  200  Exercises ...   \n",
       "426                                       Requirements   \n",
       "\n",
       "                                           description  ...   id  \\\n",
       "0    Description Interested in the field of Machine...  ...    1   \n",
       "1    Description Are you ready to start your path t...  ...    2   \n",
       "2    Description The Problem Data scientist is one ...  ...    3   \n",
       "3    Description Learn R Programming by doing! Ther...  ...    4   \n",
       "4    Description *** As seen on Kickstarter *** Art...  ...    5   \n",
       "..                                                 ...  ...  ...   \n",
       "422  Description \"Time Series Analysis and Forecast...  ...  423   \n",
       "423  Description      ...  ...  424   \n",
       "424  Description Interested in Learning Natural Lan...  ...  425   \n",
       "425  Description ----------------------------------...  ...  426   \n",
       "426  Description In this course, you will become fa...  ...  427   \n",
       "\n",
       "                                                  name  \\\n",
       "0                                     machinelearning/   \n",
       "1    python-for-data-science-and-machine-learning-b...   \n",
       "2    the-data-science-course-complete-data-science-...   \n",
       "3                                       r-programming/   \n",
       "4                                        deeplearning/   \n",
       "..                                                 ...   \n",
       "422  time-series-analysis-and-forecasting-with-python/   \n",
       "423                 artificial-intelligence-in-arabic/   \n",
       "424       nlp-bootcamp-machine-learning-deep-learning/   \n",
       "425  100-exercises-python-programming-data-science-...   \n",
       "426  python-and-machine-learning-in-financial-analy...   \n",
       "\n",
       "                                                  link  \\\n",
       "0        https://www.udemy.com/course/machinelearning/   \n",
       "1    https://www.udemy.com/course/python-for-data-s...   \n",
       "2    https://www.udemy.com/course/the-data-science-...   \n",
       "3          https://www.udemy.com/course/r-programming/   \n",
       "4           https://www.udemy.com/course/deeplearning/   \n",
       "..                                                 ...   \n",
       "422  https://www.udemy.com/course/time-series-analy...   \n",
       "423  https://www.udemy.com/course/artificial-intell...   \n",
       "424  https://www.udemy.com/course/nlp-bootcamp-mach...   \n",
       "425  https://www.udemy.com/course/100-exercises-pyt...   \n",
       "426  https://www.udemy.com/course/python-and-machin...   \n",
       "\n",
       "                                                seller  price original_price  \\\n",
       "0    Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99          84.99   \n",
       "1                                        Jose Portilla  13.99          84.99   \n",
       "2                        365 Careers  365 Careers Team  15.99          94.99   \n",
       "3        Kirill Eremenko  Ligency I Team  Ligency Team  13.99          84.99   \n",
       "4    Kirill Eremenko  Hadelin de Ponteves  Ligency ...  13.99          84.99   \n",
       "..                                                 ...    ...            ...   \n",
       "422                                     Navid Shirzadi  13.99          84.99   \n",
       "423  Dr  Ryan Ahmed  Ph D   MBA  Mitchell Bouchard ...  13.99          84.99   \n",
       "424                               Data Is Good Academy  13.99          19.99   \n",
       "425                Pawe  Krakowiak  takeITeasy Academy  13.99          19.99   \n",
       "426                                 S Emadedin Hashemi  13.99          84.99   \n",
       "\n",
       "     lectures     hours       level Tue Dec 14 05:56:01 2021  \n",
       "0         320     44.5   All Levels                      NaN  \n",
       "1         165       25   All Levels                      NaN  \n",
       "2         488       30   All Levels                      NaN  \n",
       "3          82     10.5   All Levels                      NaN  \n",
       "4         173     22.5   All Levels                      NaN  \n",
       "..        ...       ...         ...                      ...  \n",
       "422        51     10.5   All Levels                      NaN  \n",
       "423        57       10   All Levels                      NaN  \n",
       "424        62        3     Beginner                      NaN  \n",
       "425       118  1 total     Beginner                      NaN  \n",
       "426        82     20.5   All Levels                      NaN  \n",
       "\n",
       "[427 rows x 26 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df123456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
